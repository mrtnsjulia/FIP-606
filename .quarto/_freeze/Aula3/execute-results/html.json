{
  "hash": "9b1ac9ecfc6e2db81276d4d45cea377b",
  "result": {
    "engine": "knitr",
    "markdown": "# Testes Estatísticos: Comparando Grupos no R\n\nNesta aula, vamos aprender a aplicar os principais testes estatísticos usados para comparar grupos. Também vamos entender os **pressupostos de normalidade e homogeneidade de variância**, e o que fazer **quando esses pressupostos não são atendidos**. A análise é acompanhada de visualizações gráficas com o `ggplot2`.\n\n### Teste t para comparação de dois grupos independentes\n\nSerão utilizados os dados disponibilizados online na planilha `dat_mg`, que comparam o comprimento de lesões foliares sob dois tratamentos: controle e Mg2 (aplicação de magnésio), por meio da função `t.test`, nativa do R.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(gsheet)\ndat_mg <- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit?gid=983033137#gid=983033137\")\n```\n:::\n\n\nAntes de realizar testes, é sempre recomendado **explorar visualmente os dados**:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nggplot(dat_mg, aes(trat, comp)) +\n  geom_jitter(width = 0.1)\n```\n\n::: {.cell-output-display}\n![](Aula3_files/figure-html/unnamed-chunk-2-1.png){width=1344}\n:::\n:::\n\n\nO gráfico de dispersão permite visualizar que há uma diferença aparente entre os grupos, mas essa diferença precisa ser confirmada por meio de um teste estatístico. Para isso, os dados serão reorganizados no formato **largo** (wide), estrutura exigida por algumas funções do R, como o `t.test()`, quando os grupos estão em colunas separadas.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dplyr)\nlibrary(tidyverse)\ndat_mg2 <- dat_mg |>\n  pivot_wider(names_from = trat, values_from= comp)|>\n  dplyr::select(-rep)\n```\n:::\n\n\nO **teste t** é utilizado para comparar as médias de dois grupos. No exemplo abaixo, comparamos `control` e `Mg2`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nattach(dat_mg2)\nt.test(Mg2, control)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tWelch Two Sample t-test\n\ndata:  Mg2 and control\nt = -8.1549, df = 17.354, p-value = 2.423e-07\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -6.490393 -3.825607\nsample estimates:\nmean of x mean of y \n   10.520    15.678 \n```\n\n\n:::\n\n```{.r .cell-code}\nt.test(control, Mg2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tWelch Two Sample t-test\n\ndata:  control and Mg2\nt = 8.1549, df = 17.354, p-value = 2.423e-07\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n 3.825607 6.490393\nsample estimates:\nmean of x mean of y \n   15.678    10.520 \n```\n\n\n:::\n\n```{.r .cell-code}\nt.resultes <-t.test(control, Mg2, var.equal = FALSE)\n```\n:::\n\n\nPara tornar a interpretação do teste t mais acessível e descritiva, podemos utilizar o pacote `report`, que gera um resumo textual claro dos principais achados do teste. Isso facilita a comunicação dos resultados, especialmente em relatórios e apresentações.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(report)\nt.resultes <-t.test(control, Mg2, var.equal = FALSE)\nreport(t.resultes)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nEffect sizes were labelled following Cohen's (1988) recommendations.\n\nThe Welch Two Sample t-test testing the difference between control and Mg2\n(mean of x = 15.68, mean of y = 10.52) suggests that the effect is positive,\nstatistically significant, and large (difference = 5.16, 95% CI [3.83, 6.49],\nt(17.35) = 8.15, p < .001; Cohen's d = 3.65, 95% CI [2.14, 5.12])\n```\n\n\n:::\n:::\n\n\n#### **Verificação das premissas**\n\nPara garantir a confiabilidade do teste realizado, é importante verificar se os dados atendem a certas premissas, como a normalidade dos grupos e a homogeneidade das variâncias entre eles.\n\n#### Teste de normalidade\n\n-   **Histograma**\n\nO histograma permite avaliar visualmente se a normalidade é atendida nos dados. Os histogramas mostram a forma da distribuição dos dados. Buscamos uma forma aproximadamente simétrica e em sino (distribuição normal).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhist(dat_mg2$control)\n```\n\n::: {.cell-output-display}\n![](Aula3_files/figure-html/unnamed-chunk-6-1.png){width=1344}\n:::\n\n```{.r .cell-code}\nhist(dat_mg2$Mg2)\n```\n\n::: {.cell-output-display}\n![](Aula3_files/figure-html/unnamed-chunk-6-2.png){width=1344}\n:::\n:::\n\n\n-   **Shapiro-Wilk**\n\nEsse é o teste formal mais usado para verificar se uma variável segue distribuição normal. Nesse caso, será aplicada a função `shapiro.test` (nativa do R):\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshapiro.test(dat_mg2$control)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tShapiro-Wilk normality test\n\ndata:  dat_mg2$control\nW = 0.93886, p-value = 0.5404\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nshapiro.test(dat_mg2$Mg2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tShapiro-Wilk normality test\n\ndata:  dat_mg2$Mg2\nW = 0.97269, p-value = 0.9146\n```\n\n\n:::\n:::\n\n\nO teste de Shapiro-Wilk retorna um valor-p. Se **p \\> 0,05**, não há evidência contra a normalidade. Ou seja, os dados são considerados normalmente distribuídos.\n\n#### Teste de homogeneidade\n\nPara avaliar a homogeneidade entre as variantes será utilizada a função `var.test` :\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvar.test(dat_mg2$control, dat_mg2$Mg2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tF test to compare two variances\n\ndata:  dat_mg2$control and dat_mg2$Mg2\nF = 0.67654, num df = 9, denom df = 9, p-value = 0.5698\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.1680428 2.7237436\nsample estimates:\nratio of variances \n         0.6765394 \n```\n\n\n:::\n:::\n\n\nO teste de homogeneidade de variâncias também não rejeita a hipótese nula, pois o valor de **p \\> 0,05**, indicando que os tratamentos apresentam variâncias semelhantes.\n\nDessa forma, considerando a normalidade e a homogeneidade de variâncias, é possível confiar nos resultados obtidos pelo teste t.\n\n#### Teste t com `rstatix` e visualização com `ggpubr`\n\nAlém do `t.test()` nativo do R, podemos usar funções do pacote `rstatix`, que facilitam a realização de testes estatísticos com **sintaxe mais intuitiva** e integração com visualizações do `ggpubr`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(rstatix)\ntest <- t_test(comp ~ trat, data = dat_mg)\n```\n:::\n\n\nAqui estamos comparando a variável `comp` entre os níveis da variável `trat`. O objeto `test` guarda os resultados, incluindo o valor de p e o intervalo de confiança.\n\nPara facilitar a interpretação visual do teste estatístico, podemos utilizar um gráfico do tipo boxplot com o pacote `ggpubr`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggpubr)\np <- ggboxplot(\n  dat_mg, x = \"trat\", y=\"comp\",\n  color = \"trat\", palette = \"jco\")\n```\n:::\n\n\n### Teste t pareado\n\nUtilizado quando os dois grupos estão relacionados, como medidas feitas antes e depois de um tratamento nos mesmos indivíduos.\n\nAqui usaremos esse teste ao comparar a acurácia de diagnósticos com (`Aided1`) e sem (`Unaided`) suporte, onde a mesma pessoa foi avaliada nas duas condições com o objetivo de verificar se houve diferença significativa entre os dois momentos.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nescala <- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit?gid=1729131173#gid=1729131173\")\nview(escala)\n```\n:::\n\n\nO boxplot será gerado para a visualiação rápida dos dados\n\n\n::: {.cell}\n\n```{.r .cell-code}\nescala |> \n  ggplot(aes(assessment, acuracia))+\n  geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](Aula3_files/figure-html/unnamed-chunk-13-1.png){width=1344}\n:::\n:::\n\n\nSeguidamente, foram criados dois vetores separados, um para cada grupo que será comparado. No exemplo a seguir, vamos comparar a acurácia das avaliações feitas **sem auxílio (Unaided)** e **com auxílio (Aided1)**. Para isso, extraímos os valores de cada grupo da seguinte forma:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nunaided <- escala |> \n  filter(assessment == \"Unaided\") |> \n  select(acuracia)  |> \n  pull ()\n\naiaded <- escala |> \n  filter(assessment == \"Aided1\") |> \n  select(acuracia)  |> \n  pull ()\n```\n:::\n\n\n#### Verificação das premissas\n\nAntes de aplicar o teste t, devemos checar duas premissas:\n\n#### **Normalidade dos dados**\n\nUtilizamos o teste de Shapiro-Wilk para verificar se os dados de ambos os grupos seguem uma distribuição normal:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshapiro.test(unaided)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tShapiro-Wilk normality test\n\ndata:  unaided\nW = 0.7748, p-value = 0.007155\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nshapiro.test(aiaded)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tShapiro-Wilk normality test\n\ndata:  aiaded\nW = 0.92852, p-value = 0.4335\n```\n\n\n:::\n:::\n\n\nA variável `unaided` possui uma distribuição não normal, já que o p \\< 0,05. Já a variável `aiaded` possui uma distribuição normal, com p \\> 0,05.\n\n#### **Homogeneidade das variâncias**\n\nEmbora o teste t pareado seja menos sensível a isso, ainda podemos usar o `var.test` para avaliar:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvar.test(unaided, aiaded)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tF test to compare two variances\n\ndata:  unaided and aiaded\nF = 20.978, num df = 9, denom df = 9, p-value = 0.000106\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n  5.210754 84.459185\nsample estimates:\nratio of variances \n          20.97847 \n```\n\n\n:::\n:::\n\n\nOs resultados do teste apontam que os grupos têm variâncias significativamente diferentes, já que o valor de p \\< 0,05.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt.test(unaided, aiaded, paired = TRUE,\n       var.equal = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tPaired t-test\n\ndata:  unaided and aiaded\nt = -4.4214, df = 9, p-value = 0.001668\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n -0.3552353 -0.1147647\nsample estimates:\nmean difference \n         -0.235 \n```\n\n\n:::\n:::\n\n\nComo as premissas do teste t foram violadas, a melhor alternativa é usar o teste de Wilcoxon pareado, que é não paramétrico e não exige normalidade nem igualdade de variância.\n\n#### **Teste de Wilcoxon**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwilcox.test(unaided, aiaded, paired = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tWilcoxon rank sum test with continuity correction\n\ndata:  unaided and aiaded\nW = 0, p-value = 0.0001756\nalternative hypothesis: true location shift is not equal to 0\n```\n\n\n:::\n:::\n\n\nComo os grupos apresentaram valores repetidos, o R emitiu um aviso informando que o **p-valor exato** não pôde ser calculado devido a empates. Ainda assim, o resultado do teste foi computado com **correção de continuidade**, retornando um **p-valor de 0.00018**, indicando **diferença estatística significativa** entre os grupos avaliados.\n\n### Análise de variância (ANOVA)\n\nEsse teste estatístico avalia se existem diferenças significativas entre as médias de três ou mais grupos. Para realizar esse teste utilizaremos o banco de dados `micelial`, importado diretamente do Google Sheets, que contém informações sobre o crescimento micelial (em mm/dia) de diferentes espécies de fungos.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmicelial <- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit?gid=959387827#gid=959387827\")\nview(micelial)\n```\n:::\n\n\nPara verificar a distribuição dos valores de crescimento por espécie, utilizamos um boxplot com pontos de dispersão:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmicelial |> \n  ggplot(aes(especie, tcm))+\n  geom_boxplot(outlier.colour = NA)+\n  geom_jitter(width = 0.1)\n```\n\n::: {.cell-output-display}\n![](Aula3_files/figure-html/unnamed-chunk-21-1.png){width=1344}\n:::\n:::\n\n\nAplicaremos a anova:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nanova1 <- aov(tcm ~especie, data = micelial) # Ajusta um modelo de ANOVA (análise de variância) clássico\nanova2 <- lm(tcm ~especie, data = micelial) # Ajusta um modelo linear (lm = linear model), equivalente à ANOVA\nanova(anova1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Variance Table\n\nResponse: tcm\n          Df  Sum Sq Mean Sq F value    Pr(>F)    \nespecie    4 1.46958 0.36739  19.629 2.028e-07 ***\nResiduals 25 0.46792 0.01872                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n\n```{.r .cell-code}\nanova(anova2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Variance Table\n\nResponse: tcm\n          Df  Sum Sq Mean Sq F value    Pr(>F)    \nespecie    4 1.46958 0.36739  19.629 2.028e-07 ***\nResiduals 25 0.46792 0.01872                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\nO valor de p = 2.028e-07 (muito menor que 0,05) indica que há diferença significativa entre as médias das espécies.\n\n-   Como a ANOVA indica que existem diferenças significativas entre os grupos, o próximo passo fundamental é verificar se os dados atendem às premissas necessárias para a validade desse teste, ou seja, a normalidade dos resíduos e a homogeneidade das variâncias. Vamos então realizar essas checagens para garantir a confiabilidade dos resultados.\n\n#### Checagem das premissas da ANOVA\n\n-   **Histograma:**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhist(residuals(anova1))\n```\n\n::: {.cell-output-display}\n![](Aula3_files/figure-html/unnamed-chunk-23-1.png){width=1344}\n:::\n:::\n\n\n-   **Normalidade de variâncias:**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshapiro.test(residuals(anova1))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tShapiro-Wilk normality test\n\ndata:  residuals(anova1)\nW = 0.9821, p-value = 0.8782\n```\n\n\n:::\n:::\n\n\n-   **Homogeneidade de variâncias:**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbartlett.test(tcm ~ especie, data = micelial) # Mais sensível a desvios da normalidade\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tBartlett test of homogeneity of variances\n\ndata:  tcm by especie\nBartlett's K-squared = 4.4367, df = 4, p-value = 0.3501\n```\n\n\n:::\n\n```{.r .cell-code}\ninstall.packages(\"rstatix\")  # se ainda não tiver instalado\nlibrary(rstatix)\nlevene_test(tcm ~ especie, data = micelial) # Mais robusto à não normalidade)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 4\n    df1   df2 statistic     p\n  <int> <int>     <dbl> <dbl>\n1     4    25      1.76 0.169\n```\n\n\n:::\n:::\n\n\nDiante dos resultados obtidos, podemos concluir que os dados apresentam normalidade dos resíduos (p \\> 0,05) e homogeneidade de variâncias (p \\> 0,05) o que valida o uso da ANOVA paramétrica para comparar as médias de crescimento micelial entre as diferentes espécies.\n\nApesar da ANOVA indicar que **há diferença significativa entre os grupos**, ela **não informa entre quais grupos essas diferenças ocorrem**.\n\nPara isso, realizaremos agora as **comparações múltiplas** usando a função `emmeans()` (médias ajustadas) e `cld()` para visualizar quais grupos são significativamente diferentes entre si.\n\n#### Comparações múltiplas (post-hoc)\n\nPrimeiro, estimamos as médias ajustadas (ou médias marginais) para cada grupo da variável `especie`.\n\nCom essas médias, conseguimos visualizar o comportamento geral de cada grupo e, em seguida, aplicar testes de comparações múltiplas para identificar quais grupos diferem estatisticamente entre si.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(emmeans)\nm <- emmeans(anova2, ~especie)\nm\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n especie emmean     SE df lower.CL upper.CL\n Fasi     1.572 0.0559 25    1.457     1.69\n Faus     1.237 0.0559 25    1.122     1.35\n Fcor     1.322 0.0559 25    1.207     1.44\n Fgra     0.912 0.0559 25    0.797     1.03\n Fmer     1.427 0.0559 25    1.312     1.54\n\nConfidence level used: 0.95 \n```\n\n\n:::\n:::\n\n\nAgora que temos as médias ajustadas, podemos realizar as comparações entre os grupos para verificar quais espécies apresentam diferenças estatísticas significativas.\\\n\nVamos utilizar a função `cld()` do pacote **`multcompView`**, juntamente com as funções `pairs()` e `cld()` do pacote **`emmeans`**, para realizar e visualizar as comparações múltiplas entre os grupos.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n micelial <- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit?gid=959387827#gid=959387827\")\n  \n  micelial |> \n    ggplot(aes(especie, tcm))+\n    geom_boxplot(outlier.colour = NA)+\n    geom_jitter(width = 0.1)\n```\n\n::: {.cell-output-display}\n![](Aula3_files/figure-html/unnamed-chunk-27-1.png){width=1344}\n:::\n\n```{.r .cell-code}\n  anova1 <- aov(tcm ~ especie, data = micelial)\n  anova1 \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCall:\n   aov(formula = tcm ~ especie, data = micelial)\n\nTerms:\n                  especie Residuals\nSum of Squares  1.4695800 0.4679167\nDeg. of Freedom         4        25\n\nResidual standard error: 0.1368089\nEstimated effects may be unbalanced\n```\n\n\n:::\n\n```{.r .cell-code}\n  anova(anova1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Variance Table\n\nResponse: tcm\n          Df  Sum Sq Mean Sq F value    Pr(>F)    \nespecie    4 1.46958 0.36739  19.629 2.028e-07 ***\nResiduals 25 0.46792 0.01872                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n\n```{.r .cell-code}\n  anova2 <- lm(tcm ~ especie, data = micelial)\n    anova(anova2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Variance Table\n\nResponse: tcm\n          Df  Sum Sq Mean Sq F value    Pr(>F)    \nespecie    4 1.46958 0.36739  19.629 2.028e-07 ***\nResiduals 25 0.46792 0.01872                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n\n```{.r .cell-code}\n    residuals(anova1) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n          1           2           3           4           5           6 \n-0.07166667  0.01833333 -0.05166667 -0.05166667  0.02833333  0.12833333 \n          7           8           9          10          11          12 \n 0.28333333  0.01333333  0.03333333  0.06333333 -0.15666667 -0.23666667 \n         13          14          15          16          17          18 \n-0.10166667 -0.08166667 -0.12166667  0.06833333  0.10833333  0.12833333 \n         19          20          21          22          23          24 \n-0.03166667  0.06833333 -0.20166667  0.08833333 -0.01166667  0.08833333 \n         25          26          27          28          29          30 \n 0.12333333  0.19333333  0.14333333 -0.11666667 -0.14666667 -0.19666667 \n```\n\n\n:::\n\n```{.r .cell-code}\nhist(residuals(anova1))\n```\n\n::: {.cell-output-display}\n![](Aula3_files/figure-html/unnamed-chunk-27-2.png){width=1344}\n:::\n\n```{.r .cell-code}\nshapiro.test(residuals(anova1)) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tShapiro-Wilk normality test\n\ndata:  residuals(anova1)\nW = 0.9821, p-value = 0.8782\n```\n\n\n:::\n\n```{.r .cell-code}\n    bartlett.test(tcm ~ especie, data = micelial)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tBartlett test of homogeneity of variances\n\ndata:  tcm by especie\nBartlett's K-squared = 4.4367, df = 4, p-value = 0.3501\n```\n\n\n:::\n\n```{.r .cell-code}\n    levene_test(tcm ~especie, data = micelial)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 4\n    df1   df2 statistic     p\n  <int> <int>     <dbl> <dbl>\n1     4    25      1.76 0.169\n```\n\n\n:::\n\n```{.r .cell-code}\n  library(emmeans)\n   \n      m <- emmeans(anova2, ~ especie)\n  m \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n especie emmean     SE df lower.CL upper.CL\n Fasi     1.572 0.0559 25    1.457     1.69\n Faus     1.237 0.0559 25    1.122     1.35\n Fcor     1.322 0.0559 25    1.207     1.44\n Fgra     0.912 0.0559 25    0.797     1.03\n Fmer     1.427 0.0559 25    1.312     1.54\n\nConfidence level used: 0.95 \n```\n\n\n:::\n\n```{.r .cell-code}\n  library(multcomp)\n  library(multcompView)\n  \n  \n  cld(m)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n especie emmean     SE df lower.CL upper.CL .group\n Fgra     0.912 0.0559 25    0.797     1.03  1    \n Faus     1.237 0.0559 25    1.122     1.35   2   \n Fcor     1.322 0.0559 25    1.207     1.44   2   \n Fmer     1.427 0.0559 25    1.312     1.54   23  \n Fasi     1.572 0.0559 25    1.457     1.69    3  \n\nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 5 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n```\n\n\n:::\n\n```{.r .cell-code}\n pwpm(m) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n        Fasi    Faus    Fcor    Fgra    Fmer\nFasi [1.572]  0.0023  0.0302  <.0001  0.3765\nFaus   0.335 [1.237]  0.8169  0.0031  0.1469\nFcor   0.250  -0.085 [1.322]  0.0002  0.6761\nFgra   0.660   0.325   0.410 [0.912]  <.0001\nFmer   0.145  -0.190  -0.105  -0.515 [1.427]\n\nRow and column labels: especie\nUpper triangle: P values   adjust = \"tukey\"\nDiagonal: [Estimates] (emmean) \nLower triangle: Comparisons (estimate)   earlier vs. later\n```\n\n\n:::\n\n```{.r .cell-code}\n pairs(m) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n contrast    estimate    SE df t.ratio p.value\n Fasi - Faus    0.335 0.079 25   4.241  0.0023\n Fasi - Fcor    0.250 0.079 25   3.165  0.0302\n Fasi - Fgra    0.660 0.079 25   8.356  <.0001\n Fasi - Fmer    0.145 0.079 25   1.836  0.3765\n Faus - Fcor   -0.085 0.079 25  -1.076  0.8169\n Faus - Fgra    0.325 0.079 25   4.115  0.0031\n Faus - Fmer   -0.190 0.079 25  -2.405  0.1469\n Fcor - Fgra    0.410 0.079 25   5.191  0.0002\n Fcor - Fmer   -0.105 0.079 25  -1.329  0.6761\n Fgra - Fmer   -0.515 0.079 25  -6.520  <.0001\n\nP value adjustment: tukey method for comparing a family of 5 estimates \n```\n\n\n:::\n:::\n\n\n`\n\nA partir dos resultados, os grupos foram agrupados em uma tabela para facilitar a visualização das espécies que apresentam diferenças estatisticamente significativas.\n\n| Espécie | Média Ajustada (`emmean`) | Grupo (letra) |\n|---------|---------------------------|---------------|\n| Fgra    | 0.912                     | A             |\n| Faus    | 1.237                     | B             |\n| Fcor    | 1.322                     | B             |\n| Fmer    | 1.427                     | BC            |\n| Fasi    | 1.572                     | C             |\n\nCom um nível de significância de 5%, interpretamos que a espécie Fgra apresenta a menor taxa de crescimento em comparação com as demais. As espécies Faus, Fcor e Fmer possuem taxas de crescimento estatisticamente semelhantes entre si. Além disso, Fmer e Fasi também não diferem estatisticamente e apresentam as maiores taxas de crescimento.\n\n#### Testes alternativos à ANOVA: Transformações e métodos não paramétricos\n\nPara exemplificar estratégias analíticas em situações em que as **premissas da ANOVA não são atendidas**, utilizaremos um conjunto de dados chamado `InsectSprays`, disponível no próprio R. Esse conjunto simula a contagem de insetos após aplicação de diferentes tipos de pulverizações (sprays).\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninsetos <- InsectSprays\n```\n:::\n\n\nPara visualização dos dados, será construído um gráfico boxplots com pontos.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninsetos |>\n  ggplot(aes(spray, count))+\n  geom_boxplot(outlier.color = NA)+\n  geom_jitter(width = 0.1)\n```\n\n::: {.cell-output-display}\n![](Aula3_files/figure-html/unnamed-chunk-29-1.png){width=1344}\n:::\n:::\n\n\nO boxplot mostra uma comparação entre os grupos (tipos de spray). No entanto, antes de aplicar um teste paramétrico, precisamos verificar se os dados seguem distribuição normal e possuem homogeneidade de variâncias. Ajustaremos um modelo linear com os dados e esse modelo será usado para verificar se atendem às premissas da ANOVA.\n\n-   **Histograma:**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm2 <- lm(count ~ spray, data = insetos)\nhist(residuals(m2))\n```\n\n::: {.cell-output-display}\n![](Aula3_files/figure-html/unnamed-chunk-30-1.png){width=1344}\n:::\n:::\n\n\n-   **Normalidade de variâncias:**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshapiro.test(residuals(m2)) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tShapiro-Wilk normality test\n\ndata:  residuals(m2)\nW = 0.96006, p-value = 0.02226\n```\n\n\n:::\n:::\n\n\n-   **Homogeneidade de variâncias:**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbartlett.test(count ~ spray, data = insetos)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tBartlett test of homogeneity of variances\n\ndata:  count by spray\nBartlett's K-squared = 25.96, df = 5, p-value = 9.085e-05\n```\n\n\n:::\n:::\n\n\n-   **Verificação visual da normalidade dos resíduos com gráfico QQ-plot:**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nqqnorm(residuals(m2))     # Plota os resíduos esperados vs. observados\nqqline(residuals(m2))     # Adiciona a linha de referência da normalidade\n```\n\n::: {.cell-output-display}\n![](Aula3_files/figure-html/unnamed-chunk-33-1.png){width=1344}\n:::\n:::\n\n\nOs resultados indicam que os resíduos não seguem uma distribuição normal (p \\< 0,05) e que as variâncias entre os grupos não são homogêneas (p \\< 0,05), configurando uma violação das premissas da ANOVA. Essa falta de normalidade e homogeneidade também é evidenciada visualmente pelo gráfico QQ-plot e pelo histograma dos resíduos, que mostram desvios significativos da distribuição normal.\n\nDiante disso, duas abordagens alternativas podem ser adotadas:\n\n### Transformar a variável resposta\n\nUma forma de contornar a violação das premissas é transformar a variável resposta (`count`) em `ranks`, substituindo os valores originais pela sua posição ordenada. Essa abordagem diminui a influência das distribuições não normais nos resultados da análise.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm3 <- lm(rank(count) ~spray, data = insetos)\n```\n:::\n\n\nAgora vamos verificar se essa abordagem foi eficaz\n\n-   **Histograma:**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhist(residuals(m3))\n```\n\n::: {.cell-output-display}\n![](Aula3_files/figure-html/unnamed-chunk-35-1.png){width=1344}\n:::\n:::\n\n\n-   **Normalidade de variâncias:**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshapiro.test(residuals(m3))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tShapiro-Wilk normality test\n\ndata:  residuals(m3)\nW = 0.98287, p-value = 0.4342\n```\n\n\n:::\n:::\n\n\n-   **Homogeneidade de variâncias:**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbartlett.test(residuals(m3) ~ spray, data = insetos)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tBartlett test of homogeneity of variances\n\ndata:  residuals(m3) by spray\nBartlett's K-squared = 1.2924, df = 5, p-value = 0.9357\n```\n\n\n:::\n:::\n\n\n-   **Verificação visual da normalidade dos resíduos com gráfico QQ-plot:**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nqqnorm(residuals(m3))\nqqline(residuals(m3))\n```\n\n::: {.cell-output-display}\n![](Aula3_files/figure-html/unnamed-chunk-38-1.png){width=1344}\n:::\n:::\n\n\nApós a transformação os resultados indicam que os resíduos **seguem uma distribuição normal** e **homogênea** (p \\> 0,05) ), atendendo às premissas da ANOVA. Essa adequação é reforçada pelo **histograma dos resíduos**, que apresenta forma simétrica, e do **gráfico QQ-plot**, que mostra os pontos alinhados à linha teórica, sugerindo aderência à normalidade. Assim, os pressupostos estatísticos estão satisfeitos, e a ANOVA pode ser aplicada com segurança para testar diferenças entre os grupos.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nanova(m3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Variance Table\n\nResponse: rank(count)\n          Df  Sum Sq Mean Sq F value    Pr(>F)    \nspray      5 23859.3  4771.9  44.266 < 2.2e-16 ***\nResiduals 66  7114.7   107.8                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\nA ANOVA com dados transformados por postos mostrou diferença significativa entre os grupos (F = 44.266, p \\< 0,001), indicando que pelo menos um tratamento difere dos outros.\n\nAgora, para identificar quais grupos apresentam diferenças significativas após a ANOVA, utilizamos as comparações múltiplas com o pacote **`emmeans`**.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm33 <- emmeans(m3, ~ spray, type = \"response\")\ncld(m33)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n spray response SE df lower.CL upper.CL .group\n C         11.5  3 66     5.47     17.4  1    \n E         19.3  3 66    13.35     25.3  12   \n D         25.6  3 66    19.60     31.6   2   \n A         52.2  3 66    46.18     58.2    3  \n B         54.8  3 66    48.85     60.8    3  \n F         55.6  3 66    49.64     61.6    3  \n\nUnknown transformation \"rank\": no transformation done \nConfidence level used: 0.95 \nNote: contrasts are still on the rank scale. Consider using\n      regrid() if you want contrasts of back-transformed estimates. \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n```\n\n\n:::\n\n```{.r .cell-code}\nplot(m33)\n```\n\n::: {.cell-output-display}\n![](Aula3_files/figure-html/unnamed-chunk-40-1.png){width=1344}\n:::\n:::\n\n\nOs resultados mostram que os grupos se dividem em três conjuntos estatisticamente diferentes: o grupo C apresenta a menor média de resposta (11,5), seguido pelos grupos E e D com médias intermediárias (19,3 e 25,6), e os grupos A, B e F com as maiores médias (52,2; 54,8 e 55,6). Isso indica que A, B e F não diferem entre si, mas são significativamente diferentes dos demais grupos, enquanto D e E formam um grupo intermediário distinto de C e dos grupos com maiores respostas.\n\n### Testes não paramétricos\n\nQuando os dados continuam não atendendo às premissas, mesmo com transformações, utilizamos um teste não paramétrico. Nesse caso, aplicamos o teste de Kruskal-Wallis, uma alternativa à ANOVA para dados sem distribuição normal e/ou com variâncias heterogêneas.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkruskal.test(count ~ spray, data = insetos)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tKruskal-Wallis rank sum test\n\ndata:  count by spray\nKruskal-Wallis chi-squared = 54.691, df = 5, p-value = 1.511e-10\n```\n\n\n:::\n:::\n\n\nHá diferença significativa entre pelo menos dois grupos de `spray` em relação ao número de insetos (`count`), com um valor de p \\< 0,05.\n\n#### Outras formas de aplicar o teste com pacotes adicionais\n\nCom o pacote `rstatix` (para análises modernas e integração com `ggplot2`):\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(rstatix)\nkruskal_test(insetos, count ~ spray)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 6\n  .y.       n statistic    df        p method        \n* <chr> <int>     <dbl> <int>    <dbl> <chr>         \n1 count    72      54.7     5 1.51e-10 Kruskal-Wallis\n```\n\n\n:::\n:::\n",
    "supporting": [
      "Aula3_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}