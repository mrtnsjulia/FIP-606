[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Caderno de aulas",
    "section": "",
    "text": "Este caderno foi desenvolvido por Érika Carvalho e Julia Gonçalves como parte das atividades da disciplina FIP606 – Análise e Visualização de Dados, ministrada pelo professor Emerson M. Del Ponte. O material reúne conteúdos interdisciplinares voltados à aplicação de métodos estatísticos e técnicas de visualização de dados em diferentes áreas das ciências biológicas e agrárias, com ênfase na interpretação crítica e na comunicação eficaz dos resultados por meio de ferramentas como RStudio."
  },
  {
    "objectID": "Aula6.html",
    "href": "Aula6.html",
    "title": "Aula 6",
    "section": "",
    "text": "library(MASS)\ninsects &lt;- InsectSprays\n\nm1 &lt;- lm(count ~ spray, data = insects)\n\nlibrary(DHARMa)\nplot(simulateResiduals(m1))\n\n\n\n\n\n\n\n#não atendeu ao pressuposto de homogeneidade então fizemos transformação dos dados primeiro por raiz quadrada. \n\nm1 &lt;- lm(sqrt(count) ~ spray, data = insects)\nm1\n\n\nCall:\nlm(formula = sqrt(count) ~ spray, data = insects)\n\nCoefficients:\n(Intercept)       sprayB       sprayC       sprayD       sprayE       sprayF  \n     3.7607       0.1160      -2.5158      -1.5963      -1.9512       0.2579  \n\nlibrary(DHARMa)\nplot(simulateResiduals(m1))\n\n\n\n\n\n\n\n#depois fizemos transformação por log - +1 para evitar log 0\nm1_log &lt;- lm(log(count + 1) ~ spray, data = insects)\nm1_log\n\n\nCall:\nlm(formula = log(count + 1) ~ spray, data = insects)\n\nCoefficients:\n(Intercept)       sprayB       sprayC       sprayD       sprayE       sprayF  \n     2.6967       0.0598      -1.7441      -0.9834      -1.2705       0.1189  \n\nlibrary(DHARMa)\nplot(simulateResiduals(m1_log))\n\n\n\n\n\n\n\nboxcox(lm(insects$count + 0.1 ~ 1))\nb&lt;- boxcox(lm(insects$count + 0.1 ~ 1))\n\n\n\n\n\n\n\nlambda &lt;- b$x[which.max(b$y)]\nlambda\n\n[1] 0.4242424\n\nlibrary(tidyverse)\ninsects &lt;- insects |&gt;\n  mutate(count2 = count^lambda-1/lambda) |&gt;\n  mutate(count3 = sqrt(count))\n\ninsects$count2&lt;- (insects$count ^ lambda - 1) / lambda\nhist(insects$count2)\n\n\n\n\n\n\n\n\n\n\n\nlibrary(gsheet)\n\nestande &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit?gid=401662555#gid=401662555\")\n\nlibrary(ggplot2)\n estande |&gt; ggplot(aes(trat, nplants)) + geom_point() + geom_smooth(method = \"lm\", se = FALSE) +\n   facet_wrap( ~ exp) +\n   theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nexp1 &lt;- estande |&gt;\n  filter(exp == 1)\nm_exp1 &lt;- lm(nplants ~ trat, data = exp1)\nsummary(m_exp1)\n\n\nCall:\nlm(formula = nplants ~ trat, data = exp1)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-25.500  -6.532   1.758   8.573  27.226 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  52.5000     4.2044  12.487 1.84e-11 ***\ntrat         -0.2419     0.1859  -1.301    0.207    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 15 on 22 degrees of freedom\nMultiple R-squared:  0.07148,   Adjusted R-squared:  0.02928 \nF-statistic: 1.694 on 1 and 22 DF,  p-value: 0.2066\n\nexp2 &lt;- estande |&gt;\n  filter(exp == 2)\nm_exp2 &lt;- lm(nplants ~ trat, data = exp2)\nsummary(m_exp2)\n\n\nCall:\nlm(formula = nplants ~ trat, data = exp2)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-25.7816  -7.7150   0.5653   8.1929  19.2184 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  60.9857     3.6304  16.798 4.93e-14 ***\ntrat         -0.7007     0.1605  -4.365 0.000247 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.95 on 22 degrees of freedom\nMultiple R-squared:  0.4641,    Adjusted R-squared:  0.4398 \nF-statistic: 19.05 on 1 and 22 DF,  p-value: 0.0002473\n\nexp3 &lt;- estande |&gt;\n  filter(exp == 3)\nm_exp3 &lt;- lm(nplants ~ trat, data = exp3)\nsummary(m_exp3)\n\n\nCall:\nlm(formula = nplants ~ trat, data = exp3)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-26.5887  -3.9597   0.7177   5.5806  19.8952 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  95.7500     2.9529  32.425  &lt; 2e-16 ***\ntrat         -0.7634     0.1306  -5.847 6.97e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 10.53 on 22 degrees of freedom\nMultiple R-squared:  0.6085,    Adjusted R-squared:  0.5907 \nF-statistic: 34.19 on 1 and 22 DF,  p-value: 6.968e-06\n\n\n\n\n\n\nlibrary(lme4)\nm_misto &lt;- lmer(nplants ~ trat + (1 | exp/bloco), data = estande)\nsummary(m_misto)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: nplants ~ trat + (1 | exp/bloco)\n   Data: estande\n\nREML criterion at convergence: 575.8\n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-2.21697 -0.63351  0.04292  0.67094  1.92907 \n\nRandom effects:\n Groups    Name        Variance Std.Dev.\n bloco:exp (Intercept)  54.76    7.40   \n exp       (Intercept) 377.43   19.43   \n Residual              134.99   11.62   \nNumber of obs: 72, groups:  bloco:exp, 12; exp, 3\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept) 69.74524   11.57191   6.027\ntrat        -0.56869    0.08314  -6.840\n\nCorrelation of Fixed Effects:\n     (Intr)\ntrat -0.111\n\nconfint(m_misto)\n\n                 2.5 %     97.5 %\n.sig01       3.3332097 14.4218422\n.sig02       7.2377419 47.8269818\n.sigma       9.7314178 13.9359486\n(Intercept) 43.4631239 96.0274587\ntrat        -0.7328972 -0.4044812\n\ncar::Anova(m_misto)\n\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: nplants\n      Chisq Df Pr(&gt;Chisq)    \ntrat 46.788  1  7.909e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nestande |&gt;\n  ggplot(aes(trat, nplants, color = factor(exp))) +\n  geom_point()+\n  #geom_smooth(method = \"lm\", se = FALSE) +\n  geom_abline(intercept = 69.74, \n              slope = -0.568, linewidth = 2) +\n  geom_abline(intercept = 43,\n              slope = -0.73, linetype =\"dashed\") +\n    geom_abline(intercept = 96,\n              slope = -0.40, linetype =\"dashed\")\n\n\n\n\n\n\n\n\n\n\n\n\nlibrary(gsheet)\nfungi &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit?gid=465348652#gid=465348652\")\n\nfungi |&gt;\n  group_by(code, dose)  |&gt;\n  summarise(germination = mean(germination)) |&gt; \n             ggplot(aes(dose, germination)) + geom_point() +\n  geom_line() +\n  facet_wrap(~ code)\n\n\n\n\n\n\n\nFGT43 &lt;- fungi |&gt;\n  group_by(code, dose) |&gt;\n  summarise(germination = mean(germination)) |&gt;\n  filter (code == \"FGT43\")\n\nlibrary(drc)\nm43 &lt;- drm(germination ~ dose, data = FGT43,\n           fct = LL.3())\nsummary(m43)\n\n\nModel fitted: Log-logistic (ED50 as parameter) with lower limit at 0 (3 parms)\n\nParameter estimates:\n\n               Estimate Std. Error t-value   p-value    \nb:(Intercept)  1.219692   0.175081  6.9664  0.006069 ** \nd:(Intercept) 48.486911   1.456007 33.3013 5.952e-05 ***\ne:(Intercept)  0.495895   0.060851  8.1494  0.003864 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error:\n\n 1.636105 (3 degrees of freedom)\n\nAIC(m43)\n\n[1] 26.7762\n\nplot(m43)\n\n\n\n\n\n\n\nED(m43, 50)\n\n\nEstimated effective doses\n\n       Estimate Std. Error\ne:1:50 0.495895   0.060851\n\nlibrary(ec50estimator)\ndf_ec50 = estimate_EC50(germination ~ dose,\n                        data = fungi,\n                        isolate_col = \"code\",\n                        strata_col = \"state\",\n                        interval = \"delta\",\n                        fct = drc :: LL.3())\ndf_ec50 |&gt;\n  ggplot(aes(reorder(ID, Estimate), Estimate)) +\n  geom_point()+\n  coord_flip()\n\n\n\n\n\n\n\ndf_ec50 |&gt;\n  ggplot(aes(x = Estimate)) +\n  geom_histogram(bins = 5, color = \"white\")"
  },
  {
    "objectID": "Aula6.html#aula-6",
    "href": "Aula6.html#aula-6",
    "title": "Aula 6",
    "section": "",
    "text": "library(MASS)\ninsects &lt;- InsectSprays\n\nm1 &lt;- lm(count ~ spray, data = insects)\n\nlibrary(DHARMa)\nplot(simulateResiduals(m1))\n\n\n\n\n\n\n\n#não atendeu ao pressuposto de homogeneidade então fizemos transformação dos dados primeiro por raiz quadrada. \n\nm1 &lt;- lm(sqrt(count) ~ spray, data = insects)\nm1\n\n\nCall:\nlm(formula = sqrt(count) ~ spray, data = insects)\n\nCoefficients:\n(Intercept)       sprayB       sprayC       sprayD       sprayE       sprayF  \n     3.7607       0.1160      -2.5158      -1.5963      -1.9512       0.2579  \n\nlibrary(DHARMa)\nplot(simulateResiduals(m1))\n\n\n\n\n\n\n\n#depois fizemos transformação por log - +1 para evitar log 0\nm1_log &lt;- lm(log(count + 1) ~ spray, data = insects)\nm1_log\n\n\nCall:\nlm(formula = log(count + 1) ~ spray, data = insects)\n\nCoefficients:\n(Intercept)       sprayB       sprayC       sprayD       sprayE       sprayF  \n     2.6967       0.0598      -1.7441      -0.9834      -1.2705       0.1189  \n\nlibrary(DHARMa)\nplot(simulateResiduals(m1_log))\n\n\n\n\n\n\n\nboxcox(lm(insects$count + 0.1 ~ 1))\nb&lt;- boxcox(lm(insects$count + 0.1 ~ 1))\n\n\n\n\n\n\n\nlambda &lt;- b$x[which.max(b$y)]\nlambda\n\n[1] 0.4242424\n\nlibrary(tidyverse)\ninsects &lt;- insects |&gt;\n  mutate(count2 = count^lambda-1/lambda) |&gt;\n  mutate(count3 = sqrt(count))\n\ninsects$count2&lt;- (insects$count ^ lambda - 1) / lambda\nhist(insects$count2)\n\n\n\n\n\n\n\n\n\n\n\nlibrary(gsheet)\n\nestande &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit?gid=401662555#gid=401662555\")\n\nlibrary(ggplot2)\n estande |&gt; ggplot(aes(trat, nplants)) + geom_point() + geom_smooth(method = \"lm\", se = FALSE) +\n   facet_wrap( ~ exp) +\n   theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nexp1 &lt;- estande |&gt;\n  filter(exp == 1)\nm_exp1 &lt;- lm(nplants ~ trat, data = exp1)\nsummary(m_exp1)\n\n\nCall:\nlm(formula = nplants ~ trat, data = exp1)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-25.500  -6.532   1.758   8.573  27.226 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  52.5000     4.2044  12.487 1.84e-11 ***\ntrat         -0.2419     0.1859  -1.301    0.207    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 15 on 22 degrees of freedom\nMultiple R-squared:  0.07148,   Adjusted R-squared:  0.02928 \nF-statistic: 1.694 on 1 and 22 DF,  p-value: 0.2066\n\nexp2 &lt;- estande |&gt;\n  filter(exp == 2)\nm_exp2 &lt;- lm(nplants ~ trat, data = exp2)\nsummary(m_exp2)\n\n\nCall:\nlm(formula = nplants ~ trat, data = exp2)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-25.7816  -7.7150   0.5653   8.1929  19.2184 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  60.9857     3.6304  16.798 4.93e-14 ***\ntrat         -0.7007     0.1605  -4.365 0.000247 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.95 on 22 degrees of freedom\nMultiple R-squared:  0.4641,    Adjusted R-squared:  0.4398 \nF-statistic: 19.05 on 1 and 22 DF,  p-value: 0.0002473\n\nexp3 &lt;- estande |&gt;\n  filter(exp == 3)\nm_exp3 &lt;- lm(nplants ~ trat, data = exp3)\nsummary(m_exp3)\n\n\nCall:\nlm(formula = nplants ~ trat, data = exp3)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-26.5887  -3.9597   0.7177   5.5806  19.8952 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  95.7500     2.9529  32.425  &lt; 2e-16 ***\ntrat         -0.7634     0.1306  -5.847 6.97e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 10.53 on 22 degrees of freedom\nMultiple R-squared:  0.6085,    Adjusted R-squared:  0.5907 \nF-statistic: 34.19 on 1 and 22 DF,  p-value: 6.968e-06\n\n\n\n\n\n\nlibrary(lme4)\nm_misto &lt;- lmer(nplants ~ trat + (1 | exp/bloco), data = estande)\nsummary(m_misto)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: nplants ~ trat + (1 | exp/bloco)\n   Data: estande\n\nREML criterion at convergence: 575.8\n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-2.21697 -0.63351  0.04292  0.67094  1.92907 \n\nRandom effects:\n Groups    Name        Variance Std.Dev.\n bloco:exp (Intercept)  54.76    7.40   \n exp       (Intercept) 377.43   19.43   \n Residual              134.99   11.62   \nNumber of obs: 72, groups:  bloco:exp, 12; exp, 3\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept) 69.74524   11.57191   6.027\ntrat        -0.56869    0.08314  -6.840\n\nCorrelation of Fixed Effects:\n     (Intr)\ntrat -0.111\n\nconfint(m_misto)\n\n                 2.5 %     97.5 %\n.sig01       3.3332097 14.4218422\n.sig02       7.2377419 47.8269818\n.sigma       9.7314178 13.9359486\n(Intercept) 43.4631239 96.0274587\ntrat        -0.7328972 -0.4044812\n\ncar::Anova(m_misto)\n\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: nplants\n      Chisq Df Pr(&gt;Chisq)    \ntrat 46.788  1  7.909e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nestande |&gt;\n  ggplot(aes(trat, nplants, color = factor(exp))) +\n  geom_point()+\n  #geom_smooth(method = \"lm\", se = FALSE) +\n  geom_abline(intercept = 69.74, \n              slope = -0.568, linewidth = 2) +\n  geom_abline(intercept = 43,\n              slope = -0.73, linetype =\"dashed\") +\n    geom_abline(intercept = 96,\n              slope = -0.40, linetype =\"dashed\")\n\n\n\n\n\n\n\n\n\n\n\n\nlibrary(gsheet)\nfungi &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit?gid=465348652#gid=465348652\")\n\nfungi |&gt;\n  group_by(code, dose)  |&gt;\n  summarise(germination = mean(germination)) |&gt; \n             ggplot(aes(dose, germination)) + geom_point() +\n  geom_line() +\n  facet_wrap(~ code)\n\n\n\n\n\n\n\nFGT43 &lt;- fungi |&gt;\n  group_by(code, dose) |&gt;\n  summarise(germination = mean(germination)) |&gt;\n  filter (code == \"FGT43\")\n\nlibrary(drc)\nm43 &lt;- drm(germination ~ dose, data = FGT43,\n           fct = LL.3())\nsummary(m43)\n\n\nModel fitted: Log-logistic (ED50 as parameter) with lower limit at 0 (3 parms)\n\nParameter estimates:\n\n               Estimate Std. Error t-value   p-value    \nb:(Intercept)  1.219692   0.175081  6.9664  0.006069 ** \nd:(Intercept) 48.486911   1.456007 33.3013 5.952e-05 ***\ne:(Intercept)  0.495895   0.060851  8.1494  0.003864 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error:\n\n 1.636105 (3 degrees of freedom)\n\nAIC(m43)\n\n[1] 26.7762\n\nplot(m43)\n\n\n\n\n\n\n\nED(m43, 50)\n\n\nEstimated effective doses\n\n       Estimate Std. Error\ne:1:50 0.495895   0.060851\n\nlibrary(ec50estimator)\ndf_ec50 = estimate_EC50(germination ~ dose,\n                        data = fungi,\n                        isolate_col = \"code\",\n                        strata_col = \"state\",\n                        interval = \"delta\",\n                        fct = drc :: LL.3())\ndf_ec50 |&gt;\n  ggplot(aes(reorder(ID, Estimate), Estimate)) +\n  geom_point()+\n  coord_flip()\n\n\n\n\n\n\n\ndf_ec50 |&gt;\n  ggplot(aes(x = Estimate)) +\n  geom_histogram(bins = 5, color = \"white\")"
  },
  {
    "objectID": "Aula3.html",
    "href": "Aula3.html",
    "title": "Testes Estatísticos: Comparando Grupos no R",
    "section": "",
    "text": "Testes Estatísticos: Comparando Grupos no R\nNesta aula, vamos aprender a aplicar os principais testes estatísticos usados para comparar grupos. Também vamos entender os pressupostos de normalidade e homogeneidade de variância, e o que fazer quando esses pressupostos não são atendidos. A análise é acompanhada de visualizações gráficas com o ggplot2.\n\nTeste t para comparação de dois grupos independentes\nSerão utilizados os dados disponibilizados online na planilha dat_mg, que comparam o comprimento de lesões foliares sob dois tratamentos: controle e Mg2 (aplicação de magnésio), por meio da função t.test, nativa do R.\n\nlibrary(gsheet)\ndat_mg &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit?gid=983033137#gid=983033137\")\n\nAntes de realizar testes, é sempre recomendado explorar visualmente os dados:\n\nlibrary(ggplot2)\nggplot(dat_mg, aes(trat, comp)) +\n  geom_jitter(width = 0.1)\n\n\n\n\n\n\n\n\nO gráfico de dispersão permite visualizar que há uma diferença aparente entre os grupos, mas essa diferença precisa ser confirmada por meio de um teste estatístico. Para isso, os dados serão reorganizados no formato largo (wide), estrutura exigida por algumas funções do R, como o t.test(), quando os grupos estão em colunas separadas.\n\nlibrary(dplyr)\nlibrary(tidyverse)\ndat_mg2 &lt;- dat_mg |&gt;\n  pivot_wider(names_from = trat, values_from= comp)|&gt;\n  dplyr::select(-rep)\n\nO teste t é utilizado para comparar as médias de dois grupos. No exemplo abaixo, comparamos control e Mg2.\n\nattach(dat_mg2)\nt.test(Mg2, control)\n\n\n    Welch Two Sample t-test\n\ndata:  Mg2 and control\nt = -8.1549, df = 17.354, p-value = 2.423e-07\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -6.490393 -3.825607\nsample estimates:\nmean of x mean of y \n   10.520    15.678 \n\nt.test(control, Mg2)\n\n\n    Welch Two Sample t-test\n\ndata:  control and Mg2\nt = 8.1549, df = 17.354, p-value = 2.423e-07\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n 3.825607 6.490393\nsample estimates:\nmean of x mean of y \n   15.678    10.520 \n\nt.resultes &lt;-t.test(control, Mg2, var.equal = FALSE)\n\nPara tornar a interpretação do teste t mais acessível e descritiva, podemos utilizar o pacote report, que gera um resumo textual claro dos principais achados do teste. Isso facilita a comunicação dos resultados, especialmente em relatórios e apresentações.\n\nlibrary(report)\nt.resultes &lt;-t.test(control, Mg2, var.equal = FALSE)\nreport(t.resultes)\n\nEffect sizes were labelled following Cohen's (1988) recommendations.\n\nThe Welch Two Sample t-test testing the difference between control and Mg2\n(mean of x = 15.68, mean of y = 10.52) suggests that the effect is positive,\nstatistically significant, and large (difference = 5.16, 95% CI [3.83, 6.49],\nt(17.35) = 8.15, p &lt; .001; Cohen's d = 3.65, 95% CI [2.14, 5.12])\n\n\n\nVerificação das premissas\nPara garantir a confiabilidade do teste realizado, é importante verificar se os dados atendem a certas premissas, como a normalidade dos grupos e a homogeneidade das variâncias entre eles.\n\n\nTeste de normalidade\n\nHistograma\n\nO histograma permite avaliar visualmente se a normalidade é atendida nos dados. Os histogramas mostram a forma da distribuição dos dados. Buscamos uma forma aproximadamente simétrica e em sino (distribuição normal).\n\nhist(dat_mg2$control)\n\n\n\n\n\n\n\nhist(dat_mg2$Mg2)\n\n\n\n\n\n\n\n\n\nShapiro-Wilk\n\nEsse é o teste formal mais usado para verificar se uma variável segue distribuição normal. Nesse caso, será aplicada a função shapiro.test (nativa do R):\n\nshapiro.test(dat_mg2$control)\n\n\n    Shapiro-Wilk normality test\n\ndata:  dat_mg2$control\nW = 0.93886, p-value = 0.5404\n\n\n\nshapiro.test(dat_mg2$Mg2)\n\n\n    Shapiro-Wilk normality test\n\ndata:  dat_mg2$Mg2\nW = 0.97269, p-value = 0.9146\n\n\nO teste de Shapiro-Wilk retorna um valor-p. Se p &gt; 0,05, não há evidência contra a normalidade. Ou seja, os dados são considerados normalmente distribuídos.\n\n\nTeste de homogeneidade\nPara avaliar a homogeneidade entre as variantes será utilizada a função var.test :\n\nvar.test(dat_mg2$control, dat_mg2$Mg2)\n\n\n    F test to compare two variances\n\ndata:  dat_mg2$control and dat_mg2$Mg2\nF = 0.67654, num df = 9, denom df = 9, p-value = 0.5698\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.1680428 2.7237436\nsample estimates:\nratio of variances \n         0.6765394 \n\n\nO teste de homogeneidade de variâncias também não rejeita a hipótese nula, pois o valor de p &gt; 0,05, indicando que os tratamentos apresentam variâncias semelhantes.\nDessa forma, considerando a normalidade e a homogeneidade de variâncias, é possível confiar nos resultados obtidos pelo teste t.\n\n\nTeste t com rstatix e visualização com ggpubr\nAlém do t.test() nativo do R, podemos usar funções do pacote rstatix, que facilitam a realização de testes estatísticos com sintaxe mais intuitiva e integração com visualizações do ggpubr.\n\nlibrary(rstatix)\ntest &lt;- t_test(comp ~ trat, data = dat_mg)\n\nAqui estamos comparando a variável comp entre os níveis da variável trat. O objeto test guarda os resultados, incluindo o valor de p e o intervalo de confiança.\nPara facilitar a interpretação visual do teste estatístico, podemos utilizar um gráfico do tipo boxplot com o pacote ggpubr.\n\nlibrary(ggpubr)\np &lt;- ggboxplot(\n  dat_mg, x = \"trat\", y=\"comp\",\n  color = \"trat\", palette = \"jco\")\n\n\n\n\nTeste t pareado\nUtilizado quando os dois grupos estão relacionados, como medidas feitas antes e depois de um tratamento nos mesmos indivíduos.\nAqui usaremos esse teste ao comparar a acurácia de diagnósticos com (Aided1) e sem (Unaided) suporte, onde a mesma pessoa foi avaliada nas duas condições com o objetivo de verificar se houve diferença significativa entre os dois momentos.\n\nescala &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit?gid=1729131173#gid=1729131173\")\nview(escala)\n\nO boxplot será gerado para a visualiação rápida dos dados\n\nescala |&gt; \n  ggplot(aes(assessment, acuracia))+\n  geom_boxplot()\n\n\n\n\n\n\n\n\nSeguidamente, foram criados dois vetores separados, um para cada grupo que será comparado. No exemplo a seguir, vamos comparar a acurácia das avaliações feitas sem auxílio (Unaided) e com auxílio (Aided1). Para isso, extraímos os valores de cada grupo da seguinte forma:\n\nunaided &lt;- escala |&gt; \n  filter(assessment == \"Unaided\") |&gt; \n  select(acuracia)  |&gt; \n  pull ()\n\naiaded &lt;- escala |&gt; \n  filter(assessment == \"Aided1\") |&gt; \n  select(acuracia)  |&gt; \n  pull ()\n\n\nVerificação das premissas\nAntes de aplicar o teste t, devemos checar duas premissas:\n\n\nNormalidade dos dados\nUtilizamos o teste de Shapiro-Wilk para verificar se os dados de ambos os grupos seguem uma distribuição normal:\n\nshapiro.test(unaided)\n\n\n    Shapiro-Wilk normality test\n\ndata:  unaided\nW = 0.7748, p-value = 0.007155\n\n\n\nshapiro.test(aiaded)\n\n\n    Shapiro-Wilk normality test\n\ndata:  aiaded\nW = 0.92852, p-value = 0.4335\n\n\nA variável unaided possui uma distribuição não normal, já que o p &lt; 0,05. Já a variável aiaded possui uma distribuição normal, com p &gt; 0,05.\n\n\nHomogeneidade das variâncias\nEmbora o teste t pareado seja menos sensível a isso, ainda podemos usar o var.test para avaliar:\n\nvar.test(unaided, aiaded)\n\n\n    F test to compare two variances\n\ndata:  unaided and aiaded\nF = 20.978, num df = 9, denom df = 9, p-value = 0.000106\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n  5.210754 84.459185\nsample estimates:\nratio of variances \n          20.97847 \n\n\nOs resultados do teste apontam que os grupos têm variâncias significativamente diferentes, já que o valor de p &lt; 0,05.\n\nt.test(unaided, aiaded, paired = TRUE,\n       var.equal = FALSE)\n\n\n    Paired t-test\n\ndata:  unaided and aiaded\nt = -4.4214, df = 9, p-value = 0.001668\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n -0.3552353 -0.1147647\nsample estimates:\nmean difference \n         -0.235 \n\n\nComo as premissas do teste t foram violadas, a melhor alternativa é usar o teste de Wilcoxon pareado, que é não paramétrico e não exige normalidade nem igualdade de variância.\n\n\nTeste de Wilcoxon\n\nwilcox.test(unaided, aiaded, paired = FALSE)\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  unaided and aiaded\nW = 0, p-value = 0.0001756\nalternative hypothesis: true location shift is not equal to 0\n\n\nComo os grupos apresentaram valores repetidos, o R emitiu um aviso informando que o p-valor exato não pôde ser calculado devido a empates. Ainda assim, o resultado do teste foi computado com correção de continuidade, retornando um p-valor de 0.00018, indicando diferença estatística significativa entre os grupos avaliados.\n\n\n\nAnálise de variância (ANOVA)\nEsse teste estatístico avalia se existem diferenças significativas entre as médias de três ou mais grupos. Para realizar esse teste utilizaremos o banco de dados micelial, importado diretamente do Google Sheets, que contém informações sobre o crescimento micelial (em mm/dia) de diferentes espécies de fungos.\n\nmicelial &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit?gid=959387827#gid=959387827\")\nview(micelial)\n\nPara verificar a distribuição dos valores de crescimento por espécie, utilizamos um boxplot com pontos de dispersão:\n\nmicelial |&gt; \n  ggplot(aes(especie, tcm))+\n  geom_boxplot(outlier.colour = NA)+\n  geom_jitter(width = 0.1)\n\n\n\n\n\n\n\n\nAplicaremos a anova:\n\nanova1 &lt;- aov(tcm ~especie, data = micelial) # Ajusta um modelo de ANOVA (análise de variância) clássico\nanova2 &lt;- lm(tcm ~especie, data = micelial) # Ajusta um modelo linear (lm = linear model), equivalente à ANOVA\nanova(anova1)\n\nAnalysis of Variance Table\n\nResponse: tcm\n          Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \nespecie    4 1.46958 0.36739  19.629 2.028e-07 ***\nResiduals 25 0.46792 0.01872                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nanova(anova2)\n\nAnalysis of Variance Table\n\nResponse: tcm\n          Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \nespecie    4 1.46958 0.36739  19.629 2.028e-07 ***\nResiduals 25 0.46792 0.01872                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nO valor de p = 2.028e-07 (muito menor que 0,05) indica que há diferença significativa entre as médias das espécies.\n\nComo a ANOVA indica que existem diferenças significativas entre os grupos, o próximo passo fundamental é verificar se os dados atendem às premissas necessárias para a validade desse teste, ou seja, a normalidade dos resíduos e a homogeneidade das variâncias. Vamos então realizar essas checagens para garantir a confiabilidade dos resultados.\n\n\nChecagem das premissas da ANOVA\n\nHistograma:\n\n\nhist(residuals(anova1))\n\n\n\n\n\n\n\n\n\nNormalidade de variâncias:\n\n\nshapiro.test(residuals(anova1))\n\n\n    Shapiro-Wilk normality test\n\ndata:  residuals(anova1)\nW = 0.9821, p-value = 0.8782\n\n\n\nHomogeneidade de variâncias:\n\n\nbartlett.test(tcm ~ especie, data = micelial) # Mais sensível a desvios da normalidade\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  tcm by especie\nBartlett's K-squared = 4.4367, df = 4, p-value = 0.3501\n\ninstall.packages(\"rstatix\")  # se ainda não tiver instalado\nlibrary(rstatix)\nlevene_test(tcm ~ especie, data = micelial) # Mais robusto à não normalidade)\n\n# A tibble: 1 × 4\n    df1   df2 statistic     p\n  &lt;int&gt; &lt;int&gt;     &lt;dbl&gt; &lt;dbl&gt;\n1     4    25      1.76 0.169\n\n\nDiante dos resultados obtidos, podemos concluir que os dados apresentam normalidade dos resíduos (p &gt; 0,05) e homogeneidade de variâncias (p &gt; 0,05) o que valida o uso da ANOVA paramétrica para comparar as médias de crescimento micelial entre as diferentes espécies.\nApesar da ANOVA indicar que há diferença significativa entre os grupos, ela não informa entre quais grupos essas diferenças ocorrem.\nPara isso, realizaremos agora as comparações múltiplas usando a função emmeans() (médias ajustadas) e cld() para visualizar quais grupos são significativamente diferentes entre si.\n\n\nComparações múltiplas (post-hoc)\nPrimeiro, estimamos as médias ajustadas (ou médias marginais) para cada grupo da variável especie.\nCom essas médias, conseguimos visualizar o comportamento geral de cada grupo e, em seguida, aplicar testes de comparações múltiplas para identificar quais grupos diferem estatisticamente entre si.\n\nlibrary(emmeans)\nm &lt;- emmeans(anova2, ~especie)\nm\n\n especie emmean     SE df lower.CL upper.CL\n Fasi     1.572 0.0559 25    1.457     1.69\n Faus     1.237 0.0559 25    1.122     1.35\n Fcor     1.322 0.0559 25    1.207     1.44\n Fgra     0.912 0.0559 25    0.797     1.03\n Fmer     1.427 0.0559 25    1.312     1.54\n\nConfidence level used: 0.95 \n\n\nAgora que temos as médias ajustadas, podemos realizar as comparações entre os grupos para verificar quais espécies apresentam diferenças estatísticas significativas.\n\nVamos utilizar a função cld() do pacote multcompView, juntamente com as funções pairs() e cld() do pacote emmeans, para realizar e visualizar as comparações múltiplas entre os grupos.\n\n micelial &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit?gid=959387827#gid=959387827\")\n  \n  micelial |&gt; \n    ggplot(aes(especie, tcm))+\n    geom_boxplot(outlier.colour = NA)+\n    geom_jitter(width = 0.1)\n\n\n\n\n\n\n\n  anova1 &lt;- aov(tcm ~ especie, data = micelial)\n  anova1 \n\nCall:\n   aov(formula = tcm ~ especie, data = micelial)\n\nTerms:\n                  especie Residuals\nSum of Squares  1.4695800 0.4679167\nDeg. of Freedom         4        25\n\nResidual standard error: 0.1368089\nEstimated effects may be unbalanced\n\n  anova(anova1)\n\nAnalysis of Variance Table\n\nResponse: tcm\n          Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \nespecie    4 1.46958 0.36739  19.629 2.028e-07 ***\nResiduals 25 0.46792 0.01872                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n  anova2 &lt;- lm(tcm ~ especie, data = micelial)\n    anova(anova2)\n\nAnalysis of Variance Table\n\nResponse: tcm\n          Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \nespecie    4 1.46958 0.36739  19.629 2.028e-07 ***\nResiduals 25 0.46792 0.01872                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n    residuals(anova1) \n\n          1           2           3           4           5           6 \n-0.07166667  0.01833333 -0.05166667 -0.05166667  0.02833333  0.12833333 \n          7           8           9          10          11          12 \n 0.28333333  0.01333333  0.03333333  0.06333333 -0.15666667 -0.23666667 \n         13          14          15          16          17          18 \n-0.10166667 -0.08166667 -0.12166667  0.06833333  0.10833333  0.12833333 \n         19          20          21          22          23          24 \n-0.03166667  0.06833333 -0.20166667  0.08833333 -0.01166667  0.08833333 \n         25          26          27          28          29          30 \n 0.12333333  0.19333333  0.14333333 -0.11666667 -0.14666667 -0.19666667 \n\nhist(residuals(anova1))\n\n\n\n\n\n\n\nshapiro.test(residuals(anova1)) \n\n\n    Shapiro-Wilk normality test\n\ndata:  residuals(anova1)\nW = 0.9821, p-value = 0.8782\n\n    bartlett.test(tcm ~ especie, data = micelial)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  tcm by especie\nBartlett's K-squared = 4.4367, df = 4, p-value = 0.3501\n\n    levene_test(tcm ~especie, data = micelial)\n\n# A tibble: 1 × 4\n    df1   df2 statistic     p\n  &lt;int&gt; &lt;int&gt;     &lt;dbl&gt; &lt;dbl&gt;\n1     4    25      1.76 0.169\n\n  library(emmeans)\n   \n      m &lt;- emmeans(anova2, ~ especie)\n  m \n\n especie emmean     SE df lower.CL upper.CL\n Fasi     1.572 0.0559 25    1.457     1.69\n Faus     1.237 0.0559 25    1.122     1.35\n Fcor     1.322 0.0559 25    1.207     1.44\n Fgra     0.912 0.0559 25    0.797     1.03\n Fmer     1.427 0.0559 25    1.312     1.54\n\nConfidence level used: 0.95 \n\n  library(multcomp)\n  library(multcompView)\n  \n  \n  cld(m)\n\n especie emmean     SE df lower.CL upper.CL .group\n Fgra     0.912 0.0559 25    0.797     1.03  1    \n Faus     1.237 0.0559 25    1.122     1.35   2   \n Fcor     1.322 0.0559 25    1.207     1.44   2   \n Fmer     1.427 0.0559 25    1.312     1.54   23  \n Fasi     1.572 0.0559 25    1.457     1.69    3  \n\nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 5 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n pwpm(m) \n\n        Fasi    Faus    Fcor    Fgra    Fmer\nFasi [1.572]  0.0023  0.0302  &lt;.0001  0.3765\nFaus   0.335 [1.237]  0.8169  0.0031  0.1469\nFcor   0.250  -0.085 [1.322]  0.0002  0.6761\nFgra   0.660   0.325   0.410 [0.912]  &lt;.0001\nFmer   0.145  -0.190  -0.105  -0.515 [1.427]\n\nRow and column labels: especie\nUpper triangle: P values   adjust = \"tukey\"\nDiagonal: [Estimates] (emmean) \nLower triangle: Comparisons (estimate)   earlier vs. later\n\n pairs(m) \n\n contrast    estimate    SE df t.ratio p.value\n Fasi - Faus    0.335 0.079 25   4.241  0.0023\n Fasi - Fcor    0.250 0.079 25   3.165  0.0302\n Fasi - Fgra    0.660 0.079 25   8.356  &lt;.0001\n Fasi - Fmer    0.145 0.079 25   1.836  0.3765\n Faus - Fcor   -0.085 0.079 25  -1.076  0.8169\n Faus - Fgra    0.325 0.079 25   4.115  0.0031\n Faus - Fmer   -0.190 0.079 25  -2.405  0.1469\n Fcor - Fgra    0.410 0.079 25   5.191  0.0002\n Fcor - Fmer   -0.105 0.079 25  -1.329  0.6761\n Fgra - Fmer   -0.515 0.079 25  -6.520  &lt;.0001\n\nP value adjustment: tukey method for comparing a family of 5 estimates \n\n\n`\nA partir dos resultados, os grupos foram agrupados em uma tabela para facilitar a visualização das espécies que apresentam diferenças estatisticamente significativas.\n\n\n\nEspécie\nMédia Ajustada (emmean)\nGrupo (letra)\n\n\n\n\nFgra\n0.912\nA\n\n\nFaus\n1.237\nB\n\n\nFcor\n1.322\nB\n\n\nFmer\n1.427\nBC\n\n\nFasi\n1.572\nC\n\n\n\nCom um nível de significância de 5%, interpretamos que a espécie Fgra apresenta a menor taxa de crescimento em comparação com as demais. As espécies Faus, Fcor e Fmer possuem taxas de crescimento estatisticamente semelhantes entre si. Além disso, Fmer e Fasi também não diferem estatisticamente e apresentam as maiores taxas de crescimento.\n\n\nTestes alternativos à ANOVA: Transformações e métodos não paramétricos\nPara exemplificar estratégias analíticas em situações em que as premissas da ANOVA não são atendidas, utilizaremos um conjunto de dados chamado InsectSprays, disponível no próprio R. Esse conjunto simula a contagem de insetos após aplicação de diferentes tipos de pulverizações (sprays).\n\ninsetos &lt;- InsectSprays\n\nPara visualização dos dados, será construído um gráfico boxplots com pontos.\n\ninsetos |&gt;\n  ggplot(aes(spray, count))+\n  geom_boxplot(outlier.color = NA)+\n  geom_jitter(width = 0.1)\n\n\n\n\n\n\n\n\nO boxplot mostra uma comparação entre os grupos (tipos de spray). No entanto, antes de aplicar um teste paramétrico, precisamos verificar se os dados seguem distribuição normal e possuem homogeneidade de variâncias. Ajustaremos um modelo linear com os dados e esse modelo será usado para verificar se atendem às premissas da ANOVA.\n\nHistograma:\n\n\nm2 &lt;- lm(count ~ spray, data = insetos)\nhist(residuals(m2))\n\n\n\n\n\n\n\n\n\nNormalidade de variâncias:\n\n\nshapiro.test(residuals(m2)) \n\n\n    Shapiro-Wilk normality test\n\ndata:  residuals(m2)\nW = 0.96006, p-value = 0.02226\n\n\n\nHomogeneidade de variâncias:\n\n\nbartlett.test(count ~ spray, data = insetos)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  count by spray\nBartlett's K-squared = 25.96, df = 5, p-value = 9.085e-05\n\n\n\nVerificação visual da normalidade dos resíduos com gráfico QQ-plot:\n\n\nqqnorm(residuals(m2))     # Plota os resíduos esperados vs. observados\nqqline(residuals(m2))     # Adiciona a linha de referência da normalidade\n\n\n\n\n\n\n\n\nOs resultados indicam que os resíduos não seguem uma distribuição normal (p &lt; 0,05) e que as variâncias entre os grupos não são homogêneas (p &lt; 0,05), configurando uma violação das premissas da ANOVA. Essa falta de normalidade e homogeneidade também é evidenciada visualmente pelo gráfico QQ-plot e pelo histograma dos resíduos, que mostram desvios significativos da distribuição normal.\nDiante disso, duas abordagens alternativas podem ser adotadas:\n\n\n\nTransformar a variável resposta\nUma forma de contornar a violação das premissas é transformar a variável resposta (count) em ranks, substituindo os valores originais pela sua posição ordenada. Essa abordagem diminui a influência das distribuições não normais nos resultados da análise.\n\nm3 &lt;- lm(rank(count) ~spray, data = insetos)\n\nAgora vamos verificar se essa abordagem foi eficaz\n\nHistograma:\n\n\nhist(residuals(m3))\n\n\n\n\n\n\n\n\n\nNormalidade de variâncias:\n\n\nshapiro.test(residuals(m3))\n\n\n    Shapiro-Wilk normality test\n\ndata:  residuals(m3)\nW = 0.98287, p-value = 0.4342\n\n\n\nHomogeneidade de variâncias:\n\n\nbartlett.test(residuals(m3) ~ spray, data = insetos)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  residuals(m3) by spray\nBartlett's K-squared = 1.2924, df = 5, p-value = 0.9357\n\n\n\nVerificação visual da normalidade dos resíduos com gráfico QQ-plot:\n\n\nqqnorm(residuals(m3))\nqqline(residuals(m3))\n\n\n\n\n\n\n\n\nApós a transformação os resultados indicam que os resíduos seguem uma distribuição normal e homogênea (p &gt; 0,05) ), atendendo às premissas da ANOVA. Essa adequação é reforçada pelo histograma dos resíduos, que apresenta forma simétrica, e do gráfico QQ-plot, que mostra os pontos alinhados à linha teórica, sugerindo aderência à normalidade. Assim, os pressupostos estatísticos estão satisfeitos, e a ANOVA pode ser aplicada com segurança para testar diferenças entre os grupos.\n\nanova(m3)\n\nAnalysis of Variance Table\n\nResponse: rank(count)\n          Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \nspray      5 23859.3  4771.9  44.266 &lt; 2.2e-16 ***\nResiduals 66  7114.7   107.8                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nA ANOVA com dados transformados por postos mostrou diferença significativa entre os grupos (F = 44.266, p &lt; 0,001), indicando que pelo menos um tratamento difere dos outros.\nAgora, para identificar quais grupos apresentam diferenças significativas após a ANOVA, utilizamos as comparações múltiplas com o pacote emmeans.\n\nm33 &lt;- emmeans(m3, ~ spray, type = \"response\")\ncld(m33)\n\n spray response SE df lower.CL upper.CL .group\n C         11.5  3 66     5.47     17.4  1    \n E         19.3  3 66    13.35     25.3  12   \n D         25.6  3 66    19.60     31.6   2   \n A         52.2  3 66    46.18     58.2    3  \n B         54.8  3 66    48.85     60.8    3  \n F         55.6  3 66    49.64     61.6    3  \n\nUnknown transformation \"rank\": no transformation done \nConfidence level used: 0.95 \nNote: contrasts are still on the rank scale. Consider using\n      regrid() if you want contrasts of back-transformed estimates. \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\nplot(m33)\n\n\n\n\n\n\n\n\nOs resultados mostram que os grupos se dividem em três conjuntos estatisticamente diferentes: o grupo C apresenta a menor média de resposta (11,5), seguido pelos grupos E e D com médias intermediárias (19,3 e 25,6), e os grupos A, B e F com as maiores médias (52,2; 54,8 e 55,6). Isso indica que A, B e F não diferem entre si, mas são significativamente diferentes dos demais grupos, enquanto D e E formam um grupo intermediário distinto de C e dos grupos com maiores respostas.\n\n\nTestes não paramétricos\nQuando os dados continuam não atendendo às premissas, mesmo com transformações, utilizamos um teste não paramétrico. Nesse caso, aplicamos o teste de Kruskal-Wallis, uma alternativa à ANOVA para dados sem distribuição normal e/ou com variâncias heterogêneas.\n\nkruskal.test(count ~ spray, data = insetos)\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  count by spray\nKruskal-Wallis chi-squared = 54.691, df = 5, p-value = 1.511e-10\n\n\nHá diferença significativa entre pelo menos dois grupos de spray em relação ao número de insetos (count), com um valor de p &lt; 0,05.\n\nOutras formas de aplicar o teste com pacotes adicionais\nCom o pacote rstatix (para análises modernas e integração com ggplot2):\n\nlibrary(rstatix)\nkruskal_test(insetos, count ~ spray)\n\n# A tibble: 1 × 6\n  .y.       n statistic    df        p method        \n* &lt;chr&gt; &lt;int&gt;     &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;         \n1 count    72      54.7     5 1.51e-10 Kruskal-Wallis"
  },
  {
    "objectID": "Aula1.html",
    "href": "Aula1.html",
    "title": "Caderno de aulas",
    "section": "",
    "text": "Nesta aula inicial, vamos explorar os conceitos básicos dos programas R e RStudio. Você aprenderá a criar e gerenciar projetos, scripts e arquivos, além de entender como salvar seu trabalho corretamente. Também veremos o passo a passo para instalar e carregar pacotes essenciais, bem como criar estruturas de dados como vetores e data frames. Por fim, faremos algumas operações básicas no RStudio para você começar a se familiarizar com a ferramenta."
  },
  {
    "objectID": "Aula1.html#configurando-um-projeto-no-rstudio-e-criando-documentos-quarto",
    "href": "Aula1.html#configurando-um-projeto-no-rstudio-e-criando-documentos-quarto",
    "title": "Caderno de aulas",
    "section": "Configurando um Projeto no RStudio e Criando Documentos Quarto",
    "text": "Configurando um Projeto no RStudio e Criando Documentos Quarto\n\nIniciando um Projeto no RStudio\nPara organizar os arquivos da disciplina, o primeiro passo é criar um novo projeto no RStudio, isso criará uma pasta dedicada ao seu trabalho, mantendo todos os arquivos organizados em um único local. Para isso:\n\nNo menu superior do RStudio, clique em File &gt;New Project… &gt;New Directory.\nSelecione “New Project”, defina um nome para o projeto e escolha a pasta onde ele será salvo.\nFinalize clicando em “Create Project”.\n\nCriando Scripts e Documentos\nApós criar o projeto, é hora de começar a construir os arquivos onde serão escritos os códigos, comentários e interpretações.\n\nScripts R\nPara criar um novo script, onde você pode escrever e testar seus códigos em R:\nVá em File &gt;New File &gt;R Script.\nEsse tipo de arquivo é útil para testar funções, fazer experimentos com códigos e salvar pequenos trechos de análise.\nDocumentos Quarto (.qmd)\nDurante a disciplina, utilizaremos principalmente documentos no formato Quarto (.qmd). Esses arquivos permitem integrar texto, código e resultados (como gráficos e tabelas) no mesmo lugar. Para criar um documento nesse formato:\n\nAcesse File &gt;New File &gt;Quarto Document….\nNa janela seguinte, defina um título e o nome do autor.\n\nClique em Create."
  },
  {
    "objectID": "Aula1.html#importação-e-exploração-de-dados",
    "href": "Aula1.html#importação-e-exploração-de-dados",
    "title": "Caderno de aulas",
    "section": "Importação e Exploração de Dados",
    "text": "Importação e Exploração de Dados\nImportamos e exploramos o conjunto de dados Orange, que já está disponível por padrão no R. Esse banco contém informações sobre o crescimento de árvores cítricas, como a idade e a circunferência do tronco.\nAqui foi criado um objeto chamado DADOS que recebe o banco de dados Orange. O simbolo “&lt;-” é o operador de atribuição do R. Atribuindo o valor da direita ao objeto da esquerda. O operador $ foi utilizado para acessar colunas específicas, como circumference. Também utilizamos a função plot() para gerar um gráfico simples dessa variável.\n\ndados &lt;- Orange\nOrange\n\n   Tree  age circumference\n1     1  118            30\n2     1  484            58\n3     1  664            87\n4     1 1004           115\n5     1 1231           120\n6     1 1372           142\n7     1 1582           145\n8     2  118            33\n9     2  484            69\n10    2  664           111\n11    2 1004           156\n12    2 1231           172\n13    2 1372           203\n14    2 1582           203\n15    3  118            30\n16    3  484            51\n17    3  664            75\n18    3 1004           108\n19    3 1231           115\n20    3 1372           139\n21    3 1582           140\n22    4  118            32\n23    4  484            62\n24    4  664           112\n25    4 1004           167\n26    4 1231           179\n27    4 1372           209\n28    4 1582           214\n29    5  118            30\n30    5  484            49\n31    5  664            81\n32    5 1004           125\n33    5 1231           142\n34    5 1372           174\n35    5 1582           177\n\nplot(dados$circumference)"
  },
  {
    "objectID": "Aula1.html#manipulação-de-dados",
    "href": "Aula1.html#manipulação-de-dados",
    "title": "Caderno de aulas",
    "section": "Manipulação de dados",
    "text": "Manipulação de dados\nNesta etapa, trabalhamos com a criação de novos objetos a partir do conjunto de dados original dados. Essas ações são úteis para manipular partes específicas da base ou realizar transformações de maneira organizada.\n\ndados2 &lt;- dados\n\nAlém disso, foi extraida apenas a coluna circumference e armazenamos seus valores em um novo vetor chamado circ:\n\ncirc &lt;- dados$circumference\ncirc\n\n [1]  30  58  87 115 120 142 145  33  69 111 156 172 203 203  30  51  75 108 115\n[20] 139 140  32  62 112 167 179 209 214  30  49  81 125 142 174 177\n\n\nCom base nesse vetor, criamos um novo chamado circ2, no qual cada valor foi acrescido de 10 cm. Essa modificação simula um cenário hipotético de crescimento adicional no diâmetro dos troncos.\n\ncirc2 &lt;- circ+10\ncirc2\n\n [1]  40  68  97 125 130 152 155  43  79 121 166 182 213 213  40  61  85 118 125\n[20] 149 150  42  72 122 177 189 219 224  40  59  91 135 152 184 187\n\n\nTambem foi realizada a transformação logarítmica da variavél circunferência, utilizando a função log() criando uma nova coluna no próprio data frame.\n\ndados\n\n   Tree  age circumference\n1     1  118            30\n2     1  484            58\n3     1  664            87\n4     1 1004           115\n5     1 1231           120\n6     1 1372           142\n7     1 1582           145\n8     2  118            33\n9     2  484            69\n10    2  664           111\n11    2 1004           156\n12    2 1231           172\n13    2 1372           203\n14    2 1582           203\n15    3  118            30\n16    3  484            51\n17    3  664            75\n18    3 1004           108\n19    3 1231           115\n20    3 1372           139\n21    3 1582           140\n22    4  118            32\n23    4  484            62\n24    4  664           112\n25    4 1004           167\n26    4 1231           179\n27    4 1372           209\n28    4 1582           214\n29    5  118            30\n30    5  484            49\n31    5  664            81\n32    5 1004           125\n33    5 1231           142\n34    5 1372           174\n35    5 1582           177\n\ndados$logcirc &lt;- log(dados$circumferenc)\ndados\n\n   Tree  age circumference  logcirc\n1     1  118            30 3.401197\n2     1  484            58 4.060443\n3     1  664            87 4.465908\n4     1 1004           115 4.744932\n5     1 1231           120 4.787492\n6     1 1372           142 4.955827\n7     1 1582           145 4.976734\n8     2  118            33 3.496508\n9     2  484            69 4.234107\n10    2  664           111 4.709530\n11    2 1004           156 5.049856\n12    2 1231           172 5.147494\n13    2 1372           203 5.313206\n14    2 1582           203 5.313206\n15    3  118            30 3.401197\n16    3  484            51 3.931826\n17    3  664            75 4.317488\n18    3 1004           108 4.682131\n19    3 1231           115 4.744932\n20    3 1372           139 4.934474\n21    3 1582           140 4.941642\n22    4  118            32 3.465736\n23    4  484            62 4.127134\n24    4  664           112 4.718499\n25    4 1004           167 5.117994\n26    4 1231           179 5.187386\n27    4 1372           209 5.342334\n28    4 1582           214 5.365976\n29    5  118            30 3.401197\n30    5  484            49 3.891820\n31    5  664            81 4.394449\n32    5 1004           125 4.828314\n33    5 1231           142 4.955827\n34    5 1372           174 5.159055\n35    5 1582           177 5.176150\n\ndados$circumference\n\n [1]  30  58  87 115 120 142 145  33  69 111 156 172 203 203  30  51  75 108 115\n[20] 139 140  32  62 112 167 179 209 214  30  49  81 125 142 174 177\n\n\nA função attach() permite acessar diretamente as colunas de interesse sem precissar usar o $. Assim você pode chamar apenas a coluna especifica sem precisar digitar “dados$…”. E detach() desfaz o attach, sendo necessario voltar a usar o $ para acessar as colunas de interesse.\n\nattach(dados) \ncircumference\n\n [1]  30  58  87 115 120 142 145  33  69 111 156 172 203 203  30  51  75 108 115\n[20] 139 140  32  62 112 167 179 209 214  30  49  81 125 142 174 177\n\ndetach(dados)"
  },
  {
    "objectID": "Aula1.html#instalação-e-uso-de-pacotes",
    "href": "Aula1.html#instalação-e-uso-de-pacotes",
    "title": "Caderno de aulas",
    "section": "Instalação e Uso de Pacotes",
    "text": "Instalação e Uso de Pacotes\nPara utilizar funções que não estão disponíveis por padrão no R, é necessário instalar e carregar pacotes adicionais.\nAntes de usar um pacote, é necessário instalá-lo no sistema, isso pode ser feito de forma manual:\nPackages&gt; Install&gt; Na linha Packages, digite o nome do pacote de interesse, por exemplo, Agricolae&gt; Install.\nE támbem pode ser instalado usando a função:\n\ninstall.packages(\"agricolae\", repos = \"https://cloud.r-project.org\")\n\npacote 'agricolae' desempacotado com sucesso e somas MD5 verificadas\n\nOs pacotes binários baixados estão em\n    C:\\Users\\lucas\\AppData\\Local\\Temp\\Rtmp4K8GbR\\downloaded_packages\n\n\nApós a instalação, o pacote pode ser carregado em qualquer sessão do R usando a função library() .\n\nlibrary(agricolae)\n\nO pacote carregado na aula intitulado agricolae é utilizado principalmente para análises experimentais aplicadas à agricultura. Entre suas funcionalidades, estão testes estatísticos, cálculos de variáveis agronômicas e acesso a conjuntos de dados internos, exemplo corn.\nApós carregar o pacote, são criados dois vetores: dates, contendo os dias de avaliação, e severity, com os valores de severidade da doença em cada data. A função audpc() (Área Abaixo da Curva de Progresso da Doença) é utilizada para calcular uma medida acumulada da severidade ao longo do tempo. Esse valor resume a evolução da doença em um único número:\n\ndates &lt;- c(14,21,28) #cria um vetor \"c()\"\ndates\n\n[1] 14 21 28\n\nseverity &lt;- c(40,80,90)\nseverity\n\n[1] 40 80 90\n\naudpc(severity, dates)\n\nevaluation \n      1015 \n\ndata(corn)\nstr(corn)\n\n'data.frame':   34 obs. of  3 variables:\n $ method     : int  1 1 1 1 1 1 1 1 1 2 ...\n $ observation: int  83 91 94 89 89 96 91 92 90 91 ...\n $ rx         : num  11 23 28.5 17 17 31.5 23 26 19.5 23 ...\n\n\nA função str() (estrutura) mostra as variáveis presentes no conjunto, seus tipos e alguns exemplos de dados."
  },
  {
    "objectID": "Aula1.html#visualização-de-dados-com-tidyverse",
    "href": "Aula1.html#visualização-de-dados-com-tidyverse",
    "title": "Caderno de aulas",
    "section": "Visualização de Dados com tidyverse",
    "text": "Visualização de Dados com tidyverse\nO tidyverse é uma coleção de pacotes integrados (como ggplot2, dplyr, readr, entre outros) voltados para a manipulação, análise e visualização de dados.\nApós carregar o pacote, são definidos dois vetores com valores simulados:\n\nlibrary(tidyverse)\ndates &lt;- c(7,14,21,28,35,42)\nseverity &lt;- c(0.1,5,10,35,50,60)\n\nEsses vetores representam a severidade de uma doença observada ao longo de dias após o plantio. Para trabalhar com esses dados de maneira estruturada, cria-se um data.frame nomeado como data_curva, que organiza os vetores em forma de tabela:\n\ndata_curva &lt;- data.frame(dates, severity)\ndata_curva\n\n  dates severity\n1     7      0.1\n2    14      5.0\n3    21     10.0\n4    28     35.0\n5    35     50.0\n6    42     60.0\n\nstr(data_curva)\n\n'data.frame':   6 obs. of  2 variables:\n $ dates   : num  7 14 21 28 35 42\n $ severity: num  0.1 5 10 35 50 60"
  },
  {
    "objectID": "Aula1.html#criação-de-gráfico-com-ggplot2",
    "href": "Aula1.html#criação-de-gráfico-com-ggplot2",
    "title": "Caderno de aulas",
    "section": "Criação de Gráfico com ggplot2",
    "text": "Criação de Gráfico com ggplot2\nO pacote ggplot2, incluído no tidyverse, permite criar gráficos personalizados e informativos. O seguinte código produz um gráfico combinando barras, linha e pontos, representando a evolução da severidade ao longo do tempo.\nPrimeiro, uma nova variável severity2 é adicionada com valores ajustados de severidade:\n\ndata_curva |&gt; \n  mutate(severity2 = c(1, 10, 35, 58, 70, 79)) |&gt; \n  ggplot(aes(x = dates, y = severity2))+\n  geom_col()+\n  geom_line(linewidth = 2, color = \"#FA8775\") +\n  geom_point(size = 4, color = \"#FA8775\") +\n  \n  theme_classic(base_size = 14)+\n  labs(x = \"dia após plantio\",\n       y = \"Severidade (%)\")+\n  scale_y_continuous (limits = c(0, 100), n.breaks = 10)+\n  scale_x_continuous(n.breaks = 8)\n\n\n\n\n\n\n\n\nPara esse gráfico foi utilizado as seguintes funções:\n\nmutate(): cria a nova coluna severity2.\ngeom_col(): plota colunas verticais para representar os dados.\ngeom_line() e geom_point(): adicionam uma linha e pontos sobre as colunas, enfatizando a tendência dos dados.\ntheme_classic(): define um estilo visual limpo.\nlabs(): define os rótulos dos eixos.\nscale_*_continuous(): ajusta os eixos para facilitar a leitura."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "Aula 4.html",
    "href": "Aula 4.html",
    "title": "Caderno de aulas",
    "section": "",
    "text": "Nesta aula, vamos aprofundar a análise estatística utilizando modelos mais robustos e flexíveis, como o modelo linear generalizado (GLM), a ANOVA fatorial e a análise de interações entre fatores.\n\nPara isso, vamos retomar os dados da aula anterior (InsectSprays) e aplicar um modelo GLM com distribuição Poisson para contagens. Além disso, utilizaremos a ferramenta DHARMa para diagnóstico gráfico com resíduos simulados.\n\n\nDHARMa é uma ferramenta poderosa que substitui os métodos tradicionais de diagnóstico (como apenas shapiro.test() e gráficos QQ-plot) por uma abordagem mais robusta, principalmente quando saímos da ANOVA clássica e entramos em modelos transformados ou GLMs.\n\nlibrary(DHARMa)\ninsetos &lt;- InsectSprays\nm3 &lt;- lm(rank(count) ~spray, data = insetos)\nplot(simulateResiduals(m3))\n\n\n\n\n\n\n\n\nApós verificarmos a adequação do modelo transformado com o auxílio do pacote DHARMa, agora vamos explorar uma abordagem alternativa utilizando um modelo de regressão generalizada (GLM) com distribuição Poisson, que é especialmente indicado para dados de contagem como os presentes no conjunto InsectSprays."
  },
  {
    "objectID": "Aula 4.html#glm-anova-fatorial-e-interações-aplicações-práticas-no-r",
    "href": "Aula 4.html#glm-anova-fatorial-e-interações-aplicações-práticas-no-r",
    "title": "Caderno de aulas",
    "section": "",
    "text": "Nesta aula, vamos aprofundar a análise estatística utilizando modelos mais robustos e flexíveis, como o modelo linear generalizado (GLM), a ANOVA fatorial e a análise de interações entre fatores.\n\nPara isso, vamos retomar os dados da aula anterior (InsectSprays) e aplicar um modelo GLM com distribuição Poisson para contagens. Além disso, utilizaremos a ferramenta DHARMa para diagnóstico gráfico com resíduos simulados.\n\n\nDHARMa é uma ferramenta poderosa que substitui os métodos tradicionais de diagnóstico (como apenas shapiro.test() e gráficos QQ-plot) por uma abordagem mais robusta, principalmente quando saímos da ANOVA clássica e entramos em modelos transformados ou GLMs.\n\nlibrary(DHARMa)\ninsetos &lt;- InsectSprays\nm3 &lt;- lm(rank(count) ~spray, data = insetos)\nplot(simulateResiduals(m3))\n\n\n\n\n\n\n\n\nApós verificarmos a adequação do modelo transformado com o auxílio do pacote DHARMa, agora vamos explorar uma abordagem alternativa utilizando um modelo de regressão generalizada (GLM) com distribuição Poisson, que é especialmente indicado para dados de contagem como os presentes no conjunto InsectSprays."
  },
  {
    "objectID": "Aula 4.html#modelo-de-regressão-linear-generalizada-glm-c-com-distribuição-poisson",
    "href": "Aula 4.html#modelo-de-regressão-linear-generalizada-glm-c-com-distribuição-poisson",
    "title": "Caderno de aulas",
    "section": "Modelo de regressão linear generalizada (GLM) c com distribuição Poisson",
    "text": "Modelo de regressão linear generalizada (GLM) c com distribuição Poisson\nA função glm() pertence ao pacote base do R e é usada para ajustar modelos lineares generalizados. Essa função permite modelar diferentes tipos de variáveis resposta (contagem, proporção, binária, etc.) por meio da especificação de uma família de distribuição e uma função de ligação (link function).\nNeste caso, vamos usar a família poisson, que é apropriada para dados de contagem.\n\nm4 &lt;- glm(count ~ spray, data = insetos,\n          family = poisson)\n\nApós ajustar o modelo com glm(), precisamos avaliar se o fator spray tem efeito significativo sobre a variável resposta. Para isso, faremos uma análise de deviance, que é o equivalente da ANOVA nos modelos GLM.\n\nAvaliação do modelo\n\nAnálise de deviance sequencial com anova()\n\nRealiza uma análise de deviance sequencial (Type I) do modelo GLM, mostrando se os fatores incluídos influenciam significativamente a variável resposta.\n\nanova(m4)\n\nAnalysis of Deviance Table\n\nModel: poisson, link: log\n\nResponse: count\n\nTerms added sequentially (first to last)\n\n      Df Deviance Resid. Df Resid. Dev  Pr(&gt;Chi)    \nNULL                     71     409.04              \nspray  5   310.71        66      98.33 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nAnálise de Deviance Tipo II com Anova() do pacote car\n\nEssa função é uma versão mais robusta da análise de variância, que permite testar efeitos de forma mais detalhada, incluindo correções para diferentes tipos de desequilíbrios nos dados.\n\nlibrary(car)\nAnova(m4)\n\nAnalysis of Deviance Table (Type II tests)\n\nResponse: count\n      LR Chisq Df Pr(&gt;Chisq)    \nspray   310.71  5  &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nVerificação Automática das Premissas com check_model()\n\n\nlibrary(performance)\ncheck_model(m4)\n\n\n\n\n\n\n\n\n\nDiagnóstico de Resíduos Simulados com plot(simulateResiduals())\n\n\nplot(simulateResiduals(m4))\n\n\n\n\n\n\n\n\nO modelo de regressão de Poisson ajustado mostrou que o fator spray tem efeito altamente significativo sobre a variável resposta com o valor de p &lt; 0,05. Agora usaremos emmeans para descobrir onde exatamente estão essas diferenças.\n\n\nComparações múltiplas com emmeans e cld\n\nlibrary(emmeans)\nlibrary(multcomp)\nmedias_m4 &lt;- emmeans(m4, ~spray, type = \"response\")\ncld(medias_m4)\n\n spray  rate    SE  df asymp.LCL asymp.UCL .group\n C      2.08 0.417 Inf      1.41      3.08  1    \n E      3.50 0.540 Inf      2.59      4.74  12   \n D      4.92 0.640 Inf      3.81      6.35   2   \n A     14.50 1.100 Inf     12.50     16.82    3  \n B     15.33 1.130 Inf     13.27     17.72    3  \n F     16.67 1.180 Inf     14.51     19.14    3  \n\nConfidence level used: 0.95 \nIntervals are back-transformed from the log scale \nP value adjustment: tukey method for comparing a family of 6 estimates \nTests are performed on the log scale \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\nA comparação múltipla das médias ajustadas pelo modelo de Poisson, com correção de Tukey, revelou diferenças significativas entre alguns tratamentos com spray. A análise indicou que o tratamento C teve a menor média de contagem (2,08) e diferiu significativamente dos demais. Os tratamentos E (3,50) e D (4,92) apresentaram médias intermediárias. Já os tratamentos A (14,50), B (15,33) e F (16,67) tiveram as maiores médias e não diferiram entre si, formando um grupo estatisticamente semelhante."
  },
  {
    "objectID": "Aula 4.html#anova-fatorial",
    "href": "Aula 4.html#anova-fatorial",
    "title": "Caderno de aulas",
    "section": "Anova fatorial",
    "text": "Anova fatorial\nEssa análise é utilizada quando se deseja avaliar simultaneamente o efeito de dois ou mais fatores sobre uma variável resposta e investigar se existe interação entre esses fatores. Usaremos para demonstração o conjunto de dados antifungicos, disponível online, que contém informações sobre a severidade de uma doença fúngica sob diferentes tratamentos e doses aplicadas.\n\nlibrary(gsheet)\nantifungicos &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit?gid=2023059672#gid=2023059672\")\nView(antifungicos)\n\nAntes da análise estatística, vamos visualizar os dados em um três gráficos de dispersão com pontos usando geom_jitter():\n\nGráfico de dispersão por dose e tratamento:\n\n\nlibrary(tidyverse)\nantifungicos |&gt; \n  ggplot(aes(dose, severity*100))+\n  geom_jitter(width = 0.1)+\n  facet_wrap(~ treat)\n\n\n\n\n\n\n\n\n\nGráfico de interação:\n\n\ninteraction.plot(antifungicos$dose, antifungicos$treat,\n                 antifungicos$severity)\n\n\n\n\n\n\n\n\nEsse gráfico ajuda a visualizar a possível interação entre os fatores dose e treat.\n\nGráficos separados por fator (para comparação individual):\n\n\np1 &lt;- antifungicos |&gt; \n  ggplot(aes(factor(dose), severity*100))+\n  geom_jitter(width = 0.1)\n\np2 &lt;- antifungicos |&gt; \n  ggplot(aes(treat, severity*100))+\n  geom_jitter(width = 0.1)\nlibrary(patchwork)\np1+p2\n\n\n\n\n\n\n\n\nO uso do patchwork permite colocar os dois gráficos lado a lado para facilitar a comparação visual entre os fatores.\n\nAjuste do modelo linear com interação\n\nm_anti &lt;- lm(severity ~ treat*dose, data = antifungicos)\n\n\n\nAnálise de variância (ANOVA) do modelo ajustado\n\nanova(m_anti)\n\nAnalysis of Variance Table\n\nResponse: severity\n           Df   Sum Sq  Mean Sq F value    Pr(&gt;F)    \ntreat       1 0.113232 0.113232  30.358 4.754e-05 ***\ndose        1 0.073683 0.073683  19.755 0.0004077 ***\ntreat:dose  1 0.072739 0.072739  19.502 0.0004326 ***\nResiduals  16 0.059678 0.003730                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nO valor de p para a interação foi significativo (p &lt; 0,05), isso indica que o efeito da dose depende do tratamento utilizado (e vice-versa).\nSeguiremos com a verificação das premissas do modelo, garantindo que os pressupostos da ANOVA estejam sendo atendidos.\n\n\nAvaliação do modelo\n\nplot(simulateResiduals(m_anti))\n\n\n\n\n\n\n\n\n\n\nComparações múltiplas com emmeans e cld\n\nmedia_anti &lt;- emmeans(m_anti, ~ dose | treat )\nmedia_anti\n\ntreat = Ionic liquid:\n dose emmean     SE df lower.CL upper.CL\n  0.5 0.2921 0.0273 16  0.23420   0.3500\n  2.0 0.0501 0.0273 16 -0.00781   0.1080\n\ntreat = Tebuconazole:\n dose emmean     SE df lower.CL upper.CL\n  0.5 0.0210 0.0273 16 -0.03690   0.0789\n  2.0 0.0202 0.0273 16 -0.03768   0.0781\n\nConfidence level used: 0.95 \n\ncld(media_anti)\n\ntreat = Ionic liquid:\n dose emmean     SE df lower.CL upper.CL .group\n  2.0 0.0501 0.0273 16 -0.00781   0.1080  1    \n  0.5 0.2921 0.0273 16  0.23420   0.3500   2   \n\ntreat = Tebuconazole:\n dose emmean     SE df lower.CL upper.CL .group\n  2.0 0.0202 0.0273 16 -0.03768   0.0781  1    \n  0.5 0.0210 0.0273 16 -0.03690   0.0789  1    \n\nConfidence level used: 0.95 \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\nAs comparações múltiplas das médias ajustadas mostram que, no tratamento com Ionic liquid, há diferença significativa entre as doses: a dose de 0,5 apresentou severidade média significativamente maior que a dose de 2,0. Já no tratamento com Tebuconazole, as duas doses (0,5 e 2,0) não diferem estatisticamente entre si, pois compartilham o mesmo grupo na letra de agrupamento (.group = 1).\nEsses resultados indicam que o efeito da dose na severidade da doença depende do tipo de tratamento utilizado, reforçando o efeito de interação entre dose e tratamento, como apontado anteriormente na ANOVA fatorial.\n\n\nAvaliação da precisão do modelo\nPor fim, avaliamos a precisão do experimento utilizando o coeficiente de variação (CV), com a função cv.model() do pacote agricolae:\n\nlibrary(agricolae)\ncv.model(m_anti)\n\n[1] 63.7165\n\n\nO valor de CV (coeficiente de variação) calculado com cv.model(m_anti) foi de 63,72%, o que indica alta variabilidade residual em relação à média do experimento."
  },
  {
    "objectID": "Aula 4.html#análise-de-severidade-da-doença-oidio-com-interação-entre-fatores",
    "href": "Aula 4.html#análise-de-severidade-da-doença-oidio-com-interação-entre-fatores",
    "title": "Caderno de aulas",
    "section": "Análise de severidade da doença (OIDIO) com interação entre fatores",
    "text": "Análise de severidade da doença (OIDIO) com interação entre fatores\nNesta etapa, vamos utilizar o conjunto de dados PowderyMildew do pacote epifitter, que contém informações sobre a progressão da severidade da doença em diferentes tipos de irrigação e níveis de umidade.\nPrimeiramente, filtramos os dados para incluir apenas os sistemas de irrigação de interesse:\n\nlibrary(epifitter)\noidio &lt;- PowderyMildew\noidio2 &lt;- oidio |&gt; \n  dplyr::filter(irrigation_type %in% c\n         (\"MS\", \"MS above canopy\", \"Overhead\"))\n\nEm seguida, visualizamos graficamente a evolução da severidade (sev) ao longo do tempo, estratificada por tipo de irrigação e umidade:\n\nggplot(oidio2, aes(time, sev))+\n  geom_point()+\n  facet_grid(moisture ~ irrigation_type)\n\n\n\n\n\n\n\n\nPara quantificar a severidade acumulada da doença, calculamos a Área Abaixo da Curva de Progresso da Doença (AUDPC) por bloco, tipo de irrigação e umidade:\n\noidio3 &lt;- oidio2 |&gt;\n  dplyr::group_by(irrigation_type, moisture, block) |&gt;\n  dplyr::summarize(AUDPC = AUDPC(time, sev))\n\nVisualizamos os dados de AUDPC:\n\noidio3 |&gt;\n  ggplot(aes(irrigation_type, AUDPC, color = moisture))+\n  geom_point(size = 2)+\n  scale_y_continuous(limits = c(0,20))\n\n\n\n\n\n\n\n\n\nModelo linear com interação\nAjustamos um modelo linear com interação entre os fatores irrigation_type e moisture para investigar se esses fatores afetam significativamente a severidade acumulada da doença:\n\nmodel_oidio &lt;- lm(AUDPC ~ irrigation_type * moisture,\n                  data = oidio3)\nanova(model_oidio)\n\nAnalysis of Variance Table\n\nResponse: AUDPC\n                         Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \nirrigation_type           2 134.341  67.170 451.721 5.073e-12 ***\nmoisture                  1   6.680   6.680  44.924 2.188e-05 ***\nirrigation_type:moisture  2   5.104   2.552  17.162 0.0003022 ***\nResiduals                12   1.784   0.149                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nrevelou que os fatores irrigation_type (tipo de irrigação) e moisture (umidade) têm efeito estatisticamente significativo sobre a resposta AUDPC (p &lt; 0,05 para ambos). Além disso, a interação entre tipo de irrigação e umidade também foi significativa (p &lt; 0,05), indicando que o efeito de um fator depende do nível do outro. Esses resultados indicam que tanto a irrigação quanto a umidade influenciam de forma conjunta a severidade acumulada da doença ao longo do tempo.\n\n\nAvaliação das premissas do modelo\nPara verificar se os resíduos seguem uma distribuição adequada, usamos o pacote DHARMa:\n\nplot(simulateResiduals(model_oidio))\n\n\n\n\n\n\n\n\n\n\nComparações múltiplas com emmeans e cld\n\nmedias_oidio &lt;- emmeans(model_oidio, ~ moisture |\n                          irrigation_type)\n\nmedias_oidio\n\nirrigation_type = MS:\n moisture          emmean    SE df lower.CL upper.CL\n High moisture       8.52 0.223 12     8.04     9.01\n Moderate moisture  11.18 0.223 12    10.70    11.67\n\nirrigation_type = MS above canopy:\n moisture          emmean    SE df lower.CL upper.CL\n High moisture       3.99 0.223 12     3.51     4.48\n Moderate moisture   4.86 0.223 12     4.37     5.34\n\nirrigation_type = Overhead:\n moisture          emmean    SE df lower.CL upper.CL\n High moisture       3.68 0.223 12     3.20     4.17\n Moderate moisture   3.81 0.223 12     3.33     4.30\n\nConfidence level used: 0.95 \n\ncld(medias_oidio)\n\nirrigation_type = MS:\n moisture          emmean    SE df lower.CL upper.CL .group\n High moisture       8.52 0.223 12     8.04     9.01  1    \n Moderate moisture  11.18 0.223 12    10.70    11.67   2   \n\nirrigation_type = MS above canopy:\n moisture          emmean    SE df lower.CL upper.CL .group\n High moisture       3.99 0.223 12     3.51     4.48  1    \n Moderate moisture   4.86 0.223 12     4.37     5.34   2   \n\nirrigation_type = Overhead:\n moisture          emmean    SE df lower.CL upper.CL .group\n High moisture       3.68 0.223 12     3.20     4.17  1    \n Moderate moisture   3.81 0.223 12     3.33     4.30  1    \n\nConfidence level used: 0.95 \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\nAs médias ajustadas do AUDPC indicam diferenças na severidade acumulada entre os níveis de umidade dentro de cada tipo de irrigação. Para o tipo MS, a severidade foi significativamente maior na umidade moderada (11,18, grupo b) em comparação à alta umidade (8,52, grupo a), mostrando grupos estatísticos distintos. No tipo MS above canopy, também houve diferença significativa entre umidade moderada (4,86, grupo b) e alta (3,99, grupo a). Já no tipo Overhead, não houve diferença estatisticamente significativa entre os níveis de umidade, pois ambos compartilham a mesma letra de grupo (a)."
  },
  {
    "objectID": "Aula2.html",
    "href": "Aula2.html",
    "title": "Importação, Manipulação e Visualização de Dados com o R",
    "section": "",
    "text": "Nesta aula, são apresentados diferentes métodos para importar, visualizar, manipular e representar graficamente dados a partir de diversas fontes, incluindo arquivos do Excel (com extensões .xlsx e .xls), arquivos no formato .csv e planilhas hospedadas no Google Sheets.\n\n\nPara importar uma planilha do Excel com múltiplas abas, utiliza-se a função read_excel() do pacote readxl. O arquivo deve estar na mesma pasta do seu projeto.\n\nlibrary(readxl)\nlibrary(tidyverse)\ndados &lt;-read_excel(\"dados-diversos.xlsx\")\ndados\n\n# A tibble: 70 × 5\n   Cultura   rep Assess LeafDoctor ImageJ\n   &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;  &lt;dbl&gt;\n 1 Rosa       21  20.0        31.6  26.0 \n 2 Rosa       22   4.77       13.5   5.16\n 3 Rosa       23  72.1        77.6  69.5 \n 4 Rosa       24  81.4        90.8  82.7 \n 5 Rosa       25  25.8        24.5  13.1 \n 6 Rosa       26  80.4        73.8  69.9 \n 7 Rosa       27  81.7        86.8  88.7 \n 8 Rosa       28   7.02       14.0   6.4 \n 9 Rosa       29  11.2        16.0  10.8 \n10 Rosa       30  79.1        77.0  78.2 \n# ℹ 60 more rows\n\nstr(dados)\n\ntibble [70 × 5] (S3: tbl_df/tbl/data.frame)\n $ Cultura   : chr [1:70] \"Rosa\" \"Rosa\" \"Rosa\" \"Rosa\" ...\n $ rep       : num [1:70] 21 22 23 24 25 26 27 28 29 30 ...\n $ Assess    : num [1:70] 19.95 4.77 72.11 81.37 25.78 ...\n $ LeafDoctor: num [1:70] 31.6 13.5 77.6 90.8 24.5 ...\n $ ImageJ    : num [1:70] 26.04 5.16 69.46 82.68 13.13 ...\n\nglimpse(dados)\n\nRows: 70\nColumns: 5\n$ Cultura    &lt;chr&gt; \"Rosa\", \"Rosa\", \"Rosa\", \"Rosa\", \"Rosa\", \"Rosa\", \"Rosa\", \"Ro…\n$ rep        &lt;dbl&gt; 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,…\n$ Assess     &lt;dbl&gt; 19.95, 4.77, 72.11, 81.37, 25.78, 80.45, 81.69, 7.02, 11.23…\n$ LeafDoctor &lt;dbl&gt; 31.55, 13.53, 77.59, 90.83, 24.54, 73.84, 86.78, 14.04, 16.…\n$ ImageJ     &lt;dbl&gt; 26.04, 5.16, 69.46, 82.68, 13.13, 69.90, 88.66, 6.40, 10.82…\n\n\nPara acessar uma aba específica (neste caso, a terceira planilha do arquivo), é usado o argumento sheet:\n\ndados2 &lt;- read_excel(\"dados-diversos.xlsx\",\n                    sheet = 2)\ndados2 &lt;- dados2 |&gt;\n  mutate(dose = as.numeric(dose)) #Convertendo a coluna dose para formato numérico\nstr(dados2)\n\ntibble [240 × 9] (S3: tbl_df/tbl/data.frame)\n $ code       : chr [1:240] \"FGT05\" \"FGT05\" \"FGT05\" \"FGT05\" ...\n $ year       : num [1:240] 2007 2007 2007 2007 2007 ...\n $ trial      : num [1:240] 1 1 1 1 1 1 1 1 1 1 ...\n $ state      : chr [1:240] \"RS\" \"RS\" \"RS\" \"RS\" ...\n $ dose       : num [1:240] 0 0 0.05 0.05 0.5 0.5 1 1 5 5 ...\n $ replicate  : num [1:240] 1 2 1 2 1 2 1 2 1 2 ...\n $ germination: num [1:240] 46 44 18 24 9 11 0 0 0 0 ...\n $ ...8       : logi [1:240] NA NA NA NA NA NA ...\n $ ...9       : logi [1:240] NA NA NA NA NA NA ...\n\nglimpse(dados2)\n\nRows: 240\nColumns: 9\n$ code        &lt;chr&gt; \"FGT05\", \"FGT05\", \"FGT05\", \"FGT05\", \"FGT05\", \"FGT05\", \"FGT…\n$ year        &lt;dbl&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007…\n$ trial       &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ state       &lt;chr&gt; \"RS\", \"RS\", \"RS\", \"RS\", \"RS\", \"RS\", \"RS\", \"RS\", \"RS\", \"RS\"…\n$ dose        &lt;dbl&gt; 0.00, 0.00, 0.05, 0.05, 0.50, 0.50, 1.00, 1.00, 5.00, 5.00…\n$ replicate   &lt;dbl&gt; 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2…\n$ germination &lt;dbl&gt; 46, 44, 18, 24, 9, 11, 0, 0, 0, 0, 0, 0, 50, 50, 43, 44, 2…\n$ ...8        &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ...9        &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n\n\n\n\n\nÉ possível ler um arquivo .csv com a função read_csv e, em seguida, exportá-lo para o formato .xlsx, utilizando a função write_xlsx do pacote writexl .\n\ncurve &lt;- read_csv(\"curve.csv\")\n\nlibrary(writexl)\nwrite_xlsx(curve, \"curva2.xlsx\")\n\n\n\n\nDados armazenados em planilhas do Google podem ser importados diretamente por meio do pacote gsheet:\n\nlibrary(gsheet)\ndados_nuvem &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit?pli=1&gid=373270992#gid=373270992\")\nview(dados_nuvem) #possibilita a visualização dos dados\n\n\n\n\nÉ possível realizar filtragem, agrupamento e contagem de dados no R de forma simples e eficiente utilizando a combinação das funções filter(), group_by() e count() do pacote dplyr.\nPara ilustrar essas operações, será utilizado o conjunto de dados survey, importado diretamente de uma planilha do Google Sheets, contendo informações sobre espécies, resíduos e estados brasileiros ao longo dos anos.\n\nsurvey &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit?pli=1&gid=1118819738#gid=1118819738\")\nview(survey)\n\n\n\nA função group_by() organiza os dados em grupos com base em uma ou mais variáveis. Em seguida, count() contabiliza quantas observações existem em cada grupo.\nNo exemplo a seguir, agrupa-se o conjunto survey por state e residue, contando o número de registros de cada tipo de resíduo por estado:\n\nsurvey |&gt;\n  group_by(state, residue) |&gt;\n  count()\n\n# A tibble: 3 × 3\n# Groups:   state, residue [3]\n  state residue     n\n  &lt;chr&gt; &lt;chr&gt;   &lt;int&gt;\n1 PR    &lt;NA&gt;      216\n2 RS    corn      169\n3 RS    soybean   281\n\n\n\n\n\nA função filter() permite selecionar apenas as linhas que atendem a uma condição específica. Por exemplo, para obter apenas os registros do estado do Rio Grande do Sul (RS) e do Paraná (PR):\n\nRS &lt;- survey |&gt;\n  filter(state== \"RS\")\nPR &lt;- survey |&gt;\n  filter(state== \"PR\")\n\nEsses dois subconjuntos podem ser combinados em um único conjunto de dados utilizando rbind():\n\ncombinado &lt;- rbind(RS, PR)\n\n\n\n\nÉ possível selecionar apenas algumas colunas para facilitar análises específicas. Por exemplo, para trabalhar apenas com as colunas year, state e species pela função dplyr::select\n\nsurvey_b &lt;- survey |&gt;\n  dplyr::select(year, state, species)\n\nsurvey_b2009 &lt;- survey |&gt;\n  dplyr::select(year, state, species) |&gt;\n  filter(year==2009)\n\n\n\n\nPara verificar quantas vezes cada espécie foi registrada em cada ano, é possível gerar uma tabela de frequência cruzada utilizando a função tabyl() do pacote janitor .\n\nlibrary(janitor)\nsurvey_b |&gt;\n  tabyl(year, species)\n\n year Fgra Fspp\n 2009  225   40\n 2010  187   29\n 2011  140   45"
  },
  {
    "objectID": "Aula2.html#filtragem-agrupamento-e-contagem",
    "href": "Aula2.html#filtragem-agrupamento-e-contagem",
    "title": "Importação, Manipulação e Visualização de Dados com o R",
    "section": "",
    "text": "É possível realizar filtragem, agrupamento e contagem de dados no R de forma simples e eficiente utilizando a combinação das funções filter(), group_by() e count() do pacote dplyr.\nPara ilustrar essas operações, será utilizado o conjunto de dados survey, importado diretamente de uma planilha do Google Sheets, contendo informações sobre espécies, resíduos e estados brasileiros ao longo dos anos.\n\nsurvey &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit?pli=1&gid=1118819738#gid=1118819738\")\nview(survey)\n\n\n\nA função group_by() organiza os dados em grupos com base em uma ou mais variáveis. Em seguida, count() contabiliza quantas observações existem em cada grupo.\nNo exemplo a seguir, agrupa-se o conjunto survey por state e residue, contando o número de registros de cada tipo de resíduo por estado:\n\nsurvey |&gt;\n  group_by(state, residue) |&gt;\n  count()\n\n# A tibble: 3 × 3\n# Groups:   state, residue [3]\n  state residue     n\n  &lt;chr&gt; &lt;chr&gt;   &lt;int&gt;\n1 PR    &lt;NA&gt;      216\n2 RS    corn      169\n3 RS    soybean   281\n\n\n\n\n\nA função filter() permite selecionar apenas as linhas que atendem a uma condição específica. Por exemplo, para obter apenas os registros do estado do Rio Grande do Sul (RS) e do Paraná (PR):\n\nRS &lt;- survey |&gt;\n  filter(state== \"RS\")\nPR &lt;- survey |&gt;\n  filter(state== \"PR\")\n\nEsses dois subconjuntos podem ser combinados em um único conjunto de dados utilizando rbind():\n\ncombinado &lt;- rbind(RS, PR)\n\n\n\n\nÉ possível selecionar apenas algumas colunas para facilitar análises específicas. Por exemplo, para trabalhar apenas com as colunas year, state e species pela função dplyr::select\n\nsurvey_b &lt;- survey |&gt;\n  dplyr::select(year, state, species)\n\nsurvey_b2009 &lt;- survey |&gt;\n  dplyr::select(year, state, species) |&gt;\n  filter(year==2009)\n\n\n\n\nPara verificar quantas vezes cada espécie foi registrada em cada ano, é possível gerar uma tabela de frequência cruzada utilizando a função tabyl() do pacote janitor .\n\nlibrary(janitor)\nsurvey_b |&gt;\n  tabyl(year, species)\n\n year Fgra Fspp\n 2009  225   40\n 2010  187   29\n 2011  140   45"
  },
  {
    "objectID": "Aula2.html#visualização-de-dados-categóricos-com-ggplot2",
    "href": "Aula2.html#visualização-de-dados-categóricos-com-ggplot2",
    "title": "Importação, Manipulação e Visualização de Dados com o R",
    "section": "Visualização de Dados Categóricos com ggplot2",
    "text": "Visualização de Dados Categóricos com ggplot2\n\nGráfico de barras por espécie\n\nsurvey_b |&gt;\n  group_by(year, species) |&gt;\n  count() |&gt;\n  ggplot(aes(species, n)) +\n  geom_col()\n\n\n\n\n\n\n\n\nAgrupa os dados por year e species, conta o número de ocorrências e gera um gráfico de colunas com o número total de registros por espécie. Os anos estão combinados em um único painel.\n\n\nGráfico de barras por ano\n\nsurvey_b |&gt;\n  group_by(year, species) |&gt;\n  count() |&gt;\n  ggplot(aes(year, n)) +\n  geom_col()\n\n\n\n\n\n\n\n\n\n\nFacetamento por ano\n\nsurvey_b |&gt;\n  group_by(year, species) |&gt;\n  count() |&gt;\n  ggplot(aes(species, n)) +\n  geom_col() +\n  facet_wrap(~year)\n\n\n\n\n\n\n\n\nA função facet_wrap permite dividir um gráfico em múltiplos painéis, cada um representando um subconjunto dos dados baseado em uma variável categórica, no caso do exemplos os anos.\n\n\nGráfico colorido por espécie\n\nsurvey_b |&gt;\n  group_by(year, species) |&gt;\n  count() |&gt;\n  ggplot(aes(year, n, fill = species)) +\n  geom_col() +\n  scale_fill_manual(values = c(\"red\", \"purple\"))"
  },
  {
    "objectID": "Aula2.html#gráficos-de-boxplot-para-dados-quantitativos",
    "href": "Aula2.html#gráficos-de-boxplot-para-dados-quantitativos",
    "title": "Importação, Manipulação e Visualização de Dados com o R",
    "section": "Gráficos de Boxplot para Dados Quantitativos",
    "text": "Gráficos de Boxplot para Dados Quantitativos\nAlém de categorias, também podemos visualizar dados contínuos. A seguir, criam-se gráficos para variáveis numéricas utilizando boxplots, que mostram a mediana, quartis e possíveis outliers.\n\nBoxplot com dados do experimento com magnésio\nOs dados utilizados neste gráfico foram importados da planilha online. O conjunto mg contém informações sobre o comprimento de lesões sob diferentes tratamentos com magnésio.\n\nmg &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit?pli=1&gid=983033137#gid=983033137\")\nview(mg)\n\nlibrary(ggthemes)\nplot_mg &lt;- mg |&gt;\n  ggplot(aes(trat, comp))+\n  geom_boxplot(fill = \"grey\", outlier.color = NA)+\n  geom_jitter(width = 0.1, color = \"gray50\")+\n  scale_y_continuous(limits = c(0,20))+\n  labs(x= \"Tratamento\",\n       y= \"Comprimento (mm)\")\n\nCada tratamento é representado em um boxplot. Pontos individuais são sobrepostos com geom_jitter(), o que ajuda a visualizar a dispersão dos dados.\n\n\nBoxplot com taxa de crescimento micelial (tcm)\nOs dados foram obtidos da planilha online. A variável tcm representa a taxa de crescimento micelial de diferentes espécies. O gráfico abaixo mostra a comparação entre essas espécies:\n\nmicelial &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit?pli=1&gid=959387827#gid=959387827\")\nview(micelial)\n\nplot_micelial &lt;- micelial |&gt;\n ggplot(aes(reorder(especie, tcm), tcm))+\n  geom_boxplot(outlier.color = NA)+\n  geom_jitter(width = 0.1, color = \"gray50\")+\n  coord_flip()+\n  labs(x= \"\", y= \"Taxa de crescimento micelial (mm/dia)\")+\n  theme_minimal()\n\n\n\nCombinação de Gráficos com patchwork\nOs dois gráficos anteriores (magnésio e micélio) podem ser combinados em um único painel com o auxílio do pacote patchwork:\n\nlibrary(patchwork)\n(plot_mg | plot_micelial) +\n  plot_annotation(tag_levels = \"a\")\n\n\n\n\n\n\n\n\nPor fim, os gráficos que foram gerados podem ser salvos utilizando a função ggsave. Essa função salva apenaso ultimo grafico gerado.\n\nggsave(\"box.png\", bg = \"white\", width = 5, height = 5)"
  },
  {
    "objectID": "Aula5.html",
    "href": "Aula5.html",
    "title": "Caderno de aulas",
    "section": "",
    "text": "Pacotes utilizados nessa aula\n\nlibrary(gsheet)\nlibrary(ggplot2)\nlibrary(readxl)\nlibrary(tidyverse)\nlibrary(Hmisc)\nlibrary(multcomp)\nlibrary(emmeans)\n\n\ncampo &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit?gid=866852711#gid=866852711\")\nview(campo)\ncampo |&gt; \n  ggplot(aes(TRAT, PROD))+\n  geom_jitter(width = 0.1)+\n  stat_summary(\n    fun.data = \"mean_cl_boot\",\n    colour=\"red\", width = 0.3)\n\n\n\n\n\n\n\ncampo$TRAT &lt;- factor (campo$TRAT)\ncampo$BLOCO &lt;- factor (campo$BLOCO)\n\nm_campo &lt;- lm(PROD ~ BLOCO + TRAT, data = campo)\nm_campo\n\n\nCall:\nlm(formula = PROD ~ BLOCO + TRAT, data = campo)\n\nCoefficients:\n(Intercept)       BLOCO2       BLOCO3       BLOCO4        TRAT2        TRAT3  \n     4312.1       -156.4        -99.5       -115.4        715.8        890.8  \n      TRAT4        TRAT5        TRAT6        TRAT7        TRAT8  \n      921.0        902.8       1037.0        908.3        859.0  \n\nanova(m_campo)\n\nAnalysis of Variance Table\n\nResponse: PROD\n          Df  Sum Sq Mean Sq F value  Pr(&gt;F)  \nBLOCO      3  105665   35222  0.2171 0.88340  \nTRAT       7 2993906  427701  2.6367 0.04021 *\nResiduals 21 3406431  162211                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nmeans_campo &lt;- emmeans(m_campo, ~ TRAT)\nmeans_campo\n\n TRAT emmean  SE df lower.CL upper.CL\n 1      4219 201 21     3800     4638\n 2      4935 201 21     4516     5354\n 3      5110 201 21     4691     5529\n 4      5140 201 21     4721     5559\n 5      5122 201 21     4703     5541\n 6      5256 201 21     4837     5675\n 7      5128 201 21     4709     5546\n 8      5078 201 21     4659     5497\n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \n\nplot(means_campo)\n\n\n\n\n\n\n\nlibrary(multcomp)\ncld(means_campo)\n\n TRAT emmean  SE df lower.CL upper.CL .group\n 1      4219 201 21     3800     4638  1    \n 2      4935 201 21     4516     5354  12   \n 8      5078 201 21     4659     5497  12   \n 3      5110 201 21     4691     5529  12   \n 5      5122 201 21     4703     5541  12   \n 7      5128 201 21     4709     5546  12   \n 4      5140 201 21     4721     5559  12   \n 6      5256 201 21     4837     5675   2   \n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 8 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\nm_campo &lt;- lm(log(FER) ~ BLOCO + TRAT, data = campo)\nm_campo\n\n\nCall:\nlm(formula = log(FER) ~ BLOCO + TRAT, data = campo)\n\nCoefficients:\n(Intercept)       BLOCO2       BLOCO3       BLOCO4        TRAT2        TRAT3  \n     3.1347      -0.1964      -0.1878      -0.1675      -1.2600      -1.6600  \n      TRAT4        TRAT5        TRAT6        TRAT7        TRAT8  \n    -1.8718      -1.8211      -1.9052      -1.7825      -1.7491  \n\nanova(m_campo)\n\nAnalysis of Variance Table\n\nResponse: log(FER)\n          Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \nBLOCO      3  0.2064 0.06880  1.7961    0.1788    \nTRAT       7 11.5210 1.64585 42.9665 4.838e-11 ***\nResiduals 21  0.8044 0.03831                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nlibrary(DHARMa)\nplot(simulateResiduals(m_campo))\n\n\n\n\n\n\n\nmeans_campo &lt;- emmeans(m_campo, ~ TRAT, type = \"response\")\nmeans_campo\n\n TRAT response    SE df lower.CL upper.CL\n 1       20.02 1.960 21    16.33    24.54\n 2        5.68 0.556 21     4.63     6.96\n 3        3.81 0.373 21     3.11     4.67\n 4        3.08 0.301 21     2.51     3.78\n 5        3.24 0.317 21     2.64     3.97\n 6        2.98 0.292 21     2.43     3.65\n 7        3.37 0.330 21     2.75     4.13\n 8        3.48 0.341 21     2.84     4.27\n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \nIntervals are back-transformed from the log scale \n\nplot(means_campo)\n\n\n\n\n\n\n\nlibrary(multcomp)\ncld(means_campo)\n\n TRAT response    SE df lower.CL upper.CL .group\n 6        2.98 0.292 21     2.43     3.65  1    \n 4        3.08 0.301 21     2.51     3.78  1    \n 5        3.24 0.317 21     2.64     3.97  1    \n 7        3.37 0.330 21     2.75     4.13  1    \n 8        3.48 0.341 21     2.84     4.27  1    \n 3        3.81 0.373 21     3.11     4.67  12   \n 2        5.68 0.556 21     4.63     6.96   2   \n 1       20.02 1.960 21    16.33    24.54    3  \n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \nIntervals are back-transformed from the log scale \nP value adjustment: tukey method for comparing a family of 8 estimates \nTests are performed on the log scale \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\npwpm(means_campo)\n\n        1       2       3       4       5       6       7       8\n1 [20.02]  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001\n2   3.525 [ 5.68]  0.1252  0.0048  0.0110  0.0028  0.0204  0.0343\n3   5.259   1.492 [ 3.81]  0.7832  0.9335  0.6440  0.9843  0.9976\n4   6.500   1.844   1.236 [ 3.08]  0.9999  1.0000  0.9976  0.9842\n5   6.178   1.753   1.175   0.951 [ 3.24]  0.9984  1.0000  0.9994\n6   6.721   1.906   1.278   1.034   1.088 [ 2.98]  0.9842  0.9431\n7   5.945   1.686   1.130   0.915   0.962   0.885 [ 3.37]  1.0000\n8   5.750   1.631   1.093   0.885   0.931   0.856   0.967 [ 3.48]\n\nRow and column labels: TRAT\nUpper triangle: P values   null = 1  adjust = \"tukey\"\nDiagonal: [Estimates] (response)   type = \"response\"\nLower triangle: Comparisons (ratio)   earlier vs. later\n\n\n\n\n\n\n\n\nmilho &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit?gid=1345524759#gid=1345524759\")\nview(milho)\n\nmilho |&gt; \n  ggplot(aes(hybrid, index, color = method))+\n  geom_jitter(width = 0.1)+\n  coord_flip()\n\n\n\n\n\n\n\nmilho$hybrid_block &lt;- interaction(milho$hybrid, milho$block)\n\nlibrary(dplyr)\nmilho |&gt; \n  mutate(hybrid_block = interaction(hybrid, block))\n\n# A tibble: 48 × 6\n   hybrid   block method index yield hybrid_block\n   &lt;chr&gt;    &lt;dbl&gt; &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;       \n 1 30F53 HX     1 pin     21.1 12920 30F53 HX.1  \n 2 30F53 HX     2 pin     21.1  9870 30F53 HX.2  \n 3 30F53 HX     3 pin     23.3  8920 30F53 HX.3  \n 4 30F53 HX     4 pin     35.6 13120 30F53 HX.4  \n 5 30F53 YH     1 pin     21.1 12060 30F53 YH.1  \n 6 30F53 YH     2 pin     22.2  7860 30F53 YH.2  \n 7 30F53 YH     3 pin     27.3  7410 30F53 YH.3  \n 8 30F53 YH     4 pin     27.8 10300 30F53 YH.4  \n 9 30K64        1 pin     20   11700 30K64.1     \n10 30K64        2 pin     20   10700 30K64.2     \n# ℹ 38 more rows\n\nlibrary(DHARMa)\nlibrary(lme4)\nm_milho &lt;- lmer(index ~ hybrid*method + \n                  (1 | block:hybrid_block),\n                data = milho)\ncar::Anova(m_milho)\n\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: index\n                Chisq Df Pr(&gt;Chisq)   \nhybrid        11.4239  5    0.04359 * \nmethod         4.6964  1    0.03023 * \nhybrid:method 15.8062  5    0.00742 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nplot(simulateResiduals(m_milho))\n\n\n\n\n\n\n\nlibrary(multcomp)\nmedia_milho &lt;- emmeans(m_milho, ~ hybrid | method)\ncld (media_milho, Letters = letters)\n\nmethod = pin:\n hybrid   emmean   SE   df lower.CL upper.CL .group\n BG7049H    19.4 3.57 24.9     12.1     26.8  a    \n 30K64      20.6 3.57 24.9     13.2     27.9  a    \n 30F53 YH   24.6 3.57 24.9     17.3     31.9  ab   \n 30F53 HX   25.3 3.57 24.9     17.9     32.6  ab   \n 30S31YH    32.5 3.57 24.9     25.2     39.8  ab   \n 30S31H     38.1 3.57 24.9     30.8     45.4   b   \n\nmethod = silk:\n hybrid   emmean   SE   df lower.CL upper.CL .group\n BG7049H    19.2 3.57 24.9     11.8     26.5  a    \n 30K64      21.5 3.57 24.9     14.2     28.8  a    \n 30F53 HX   25.0 3.57 24.9     17.7     32.3  a    \n 30F53 YH   26.2 3.57 24.9     18.9     33.6  a    \n 30S31H     26.5 3.57 24.9     19.2     33.8  a    \n 30S31YH    26.6 3.57 24.9     19.3     34.0  a    \n\nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\nm_milho3 &lt;- lmer(yield ~ hybrid*method + \n                  (1 | block:hybrid_block),\n                data = milho)\ncar::Anova(m_milho3)\n\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: yield\n                Chisq Df Pr(&gt;Chisq)    \nhybrid        22.5966  5  0.0004031 ***\nmethod         0.1052  1  0.7456932    \nhybrid:method 25.9302  5  9.206e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nplot(simulateResiduals(m_milho3))\n\n\n\n\n\n\n\n\n\n\n\n\nlibrary(ggplot2)\nmilho |&gt; \n  ggplot(aes(index,  yield))+\n  geom_point()+\n  geom_smooth(method = \"lm\")\n\n\n\n\n\n\n\ncor1 &lt;- cor.test(milho$index, milho$yield)\nR2_percentual &lt;- (cor1$estimate)^2 * 100\nR2_percentual*100\n\n     cor \n632.3713"
  },
  {
    "objectID": "Aula5.html#aula-5",
    "href": "Aula5.html#aula-5",
    "title": "Caderno de aulas",
    "section": "",
    "text": "Pacotes utilizados nessa aula\n\nlibrary(gsheet)\nlibrary(ggplot2)\nlibrary(readxl)\nlibrary(tidyverse)\nlibrary(Hmisc)\nlibrary(multcomp)\nlibrary(emmeans)\n\n\ncampo &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit?gid=866852711#gid=866852711\")\nview(campo)\ncampo |&gt; \n  ggplot(aes(TRAT, PROD))+\n  geom_jitter(width = 0.1)+\n  stat_summary(\n    fun.data = \"mean_cl_boot\",\n    colour=\"red\", width = 0.3)\n\n\n\n\n\n\n\ncampo$TRAT &lt;- factor (campo$TRAT)\ncampo$BLOCO &lt;- factor (campo$BLOCO)\n\nm_campo &lt;- lm(PROD ~ BLOCO + TRAT, data = campo)\nm_campo\n\n\nCall:\nlm(formula = PROD ~ BLOCO + TRAT, data = campo)\n\nCoefficients:\n(Intercept)       BLOCO2       BLOCO3       BLOCO4        TRAT2        TRAT3  \n     4312.1       -156.4        -99.5       -115.4        715.8        890.8  \n      TRAT4        TRAT5        TRAT6        TRAT7        TRAT8  \n      921.0        902.8       1037.0        908.3        859.0  \n\nanova(m_campo)\n\nAnalysis of Variance Table\n\nResponse: PROD\n          Df  Sum Sq Mean Sq F value  Pr(&gt;F)  \nBLOCO      3  105665   35222  0.2171 0.88340  \nTRAT       7 2993906  427701  2.6367 0.04021 *\nResiduals 21 3406431  162211                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nmeans_campo &lt;- emmeans(m_campo, ~ TRAT)\nmeans_campo\n\n TRAT emmean  SE df lower.CL upper.CL\n 1      4219 201 21     3800     4638\n 2      4935 201 21     4516     5354\n 3      5110 201 21     4691     5529\n 4      5140 201 21     4721     5559\n 5      5122 201 21     4703     5541\n 6      5256 201 21     4837     5675\n 7      5128 201 21     4709     5546\n 8      5078 201 21     4659     5497\n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \n\nplot(means_campo)\n\n\n\n\n\n\n\nlibrary(multcomp)\ncld(means_campo)\n\n TRAT emmean  SE df lower.CL upper.CL .group\n 1      4219 201 21     3800     4638  1    \n 2      4935 201 21     4516     5354  12   \n 8      5078 201 21     4659     5497  12   \n 3      5110 201 21     4691     5529  12   \n 5      5122 201 21     4703     5541  12   \n 7      5128 201 21     4709     5546  12   \n 4      5140 201 21     4721     5559  12   \n 6      5256 201 21     4837     5675   2   \n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 8 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\nm_campo &lt;- lm(log(FER) ~ BLOCO + TRAT, data = campo)\nm_campo\n\n\nCall:\nlm(formula = log(FER) ~ BLOCO + TRAT, data = campo)\n\nCoefficients:\n(Intercept)       BLOCO2       BLOCO3       BLOCO4        TRAT2        TRAT3  \n     3.1347      -0.1964      -0.1878      -0.1675      -1.2600      -1.6600  \n      TRAT4        TRAT5        TRAT6        TRAT7        TRAT8  \n    -1.8718      -1.8211      -1.9052      -1.7825      -1.7491  \n\nanova(m_campo)\n\nAnalysis of Variance Table\n\nResponse: log(FER)\n          Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \nBLOCO      3  0.2064 0.06880  1.7961    0.1788    \nTRAT       7 11.5210 1.64585 42.9665 4.838e-11 ***\nResiduals 21  0.8044 0.03831                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nlibrary(DHARMa)\nplot(simulateResiduals(m_campo))\n\n\n\n\n\n\n\nmeans_campo &lt;- emmeans(m_campo, ~ TRAT, type = \"response\")\nmeans_campo\n\n TRAT response    SE df lower.CL upper.CL\n 1       20.02 1.960 21    16.33    24.54\n 2        5.68 0.556 21     4.63     6.96\n 3        3.81 0.373 21     3.11     4.67\n 4        3.08 0.301 21     2.51     3.78\n 5        3.24 0.317 21     2.64     3.97\n 6        2.98 0.292 21     2.43     3.65\n 7        3.37 0.330 21     2.75     4.13\n 8        3.48 0.341 21     2.84     4.27\n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \nIntervals are back-transformed from the log scale \n\nplot(means_campo)\n\n\n\n\n\n\n\nlibrary(multcomp)\ncld(means_campo)\n\n TRAT response    SE df lower.CL upper.CL .group\n 6        2.98 0.292 21     2.43     3.65  1    \n 4        3.08 0.301 21     2.51     3.78  1    \n 5        3.24 0.317 21     2.64     3.97  1    \n 7        3.37 0.330 21     2.75     4.13  1    \n 8        3.48 0.341 21     2.84     4.27  1    \n 3        3.81 0.373 21     3.11     4.67  12   \n 2        5.68 0.556 21     4.63     6.96   2   \n 1       20.02 1.960 21    16.33    24.54    3  \n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \nIntervals are back-transformed from the log scale \nP value adjustment: tukey method for comparing a family of 8 estimates \nTests are performed on the log scale \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\npwpm(means_campo)\n\n        1       2       3       4       5       6       7       8\n1 [20.02]  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001\n2   3.525 [ 5.68]  0.1252  0.0048  0.0110  0.0028  0.0204  0.0343\n3   5.259   1.492 [ 3.81]  0.7832  0.9335  0.6440  0.9843  0.9976\n4   6.500   1.844   1.236 [ 3.08]  0.9999  1.0000  0.9976  0.9842\n5   6.178   1.753   1.175   0.951 [ 3.24]  0.9984  1.0000  0.9994\n6   6.721   1.906   1.278   1.034   1.088 [ 2.98]  0.9842  0.9431\n7   5.945   1.686   1.130   0.915   0.962   0.885 [ 3.37]  1.0000\n8   5.750   1.631   1.093   0.885   0.931   0.856   0.967 [ 3.48]\n\nRow and column labels: TRAT\nUpper triangle: P values   null = 1  adjust = \"tukey\"\nDiagonal: [Estimates] (response)   type = \"response\"\nLower triangle: Comparisons (ratio)   earlier vs. later\n\n\n\n\n\n\n\n\nmilho &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit?gid=1345524759#gid=1345524759\")\nview(milho)\n\nmilho |&gt; \n  ggplot(aes(hybrid, index, color = method))+\n  geom_jitter(width = 0.1)+\n  coord_flip()\n\n\n\n\n\n\n\nmilho$hybrid_block &lt;- interaction(milho$hybrid, milho$block)\n\nlibrary(dplyr)\nmilho |&gt; \n  mutate(hybrid_block = interaction(hybrid, block))\n\n# A tibble: 48 × 6\n   hybrid   block method index yield hybrid_block\n   &lt;chr&gt;    &lt;dbl&gt; &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;       \n 1 30F53 HX     1 pin     21.1 12920 30F53 HX.1  \n 2 30F53 HX     2 pin     21.1  9870 30F53 HX.2  \n 3 30F53 HX     3 pin     23.3  8920 30F53 HX.3  \n 4 30F53 HX     4 pin     35.6 13120 30F53 HX.4  \n 5 30F53 YH     1 pin     21.1 12060 30F53 YH.1  \n 6 30F53 YH     2 pin     22.2  7860 30F53 YH.2  \n 7 30F53 YH     3 pin     27.3  7410 30F53 YH.3  \n 8 30F53 YH     4 pin     27.8 10300 30F53 YH.4  \n 9 30K64        1 pin     20   11700 30K64.1     \n10 30K64        2 pin     20   10700 30K64.2     \n# ℹ 38 more rows\n\nlibrary(DHARMa)\nlibrary(lme4)\nm_milho &lt;- lmer(index ~ hybrid*method + \n                  (1 | block:hybrid_block),\n                data = milho)\ncar::Anova(m_milho)\n\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: index\n                Chisq Df Pr(&gt;Chisq)   \nhybrid        11.4239  5    0.04359 * \nmethod         4.6964  1    0.03023 * \nhybrid:method 15.8062  5    0.00742 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nplot(simulateResiduals(m_milho))\n\n\n\n\n\n\n\nlibrary(multcomp)\nmedia_milho &lt;- emmeans(m_milho, ~ hybrid | method)\ncld (media_milho, Letters = letters)\n\nmethod = pin:\n hybrid   emmean   SE   df lower.CL upper.CL .group\n BG7049H    19.4 3.57 24.9     12.1     26.8  a    \n 30K64      20.6 3.57 24.9     13.2     27.9  a    \n 30F53 YH   24.6 3.57 24.9     17.3     31.9  ab   \n 30F53 HX   25.3 3.57 24.9     17.9     32.6  ab   \n 30S31YH    32.5 3.57 24.9     25.2     39.8  ab   \n 30S31H     38.1 3.57 24.9     30.8     45.4   b   \n\nmethod = silk:\n hybrid   emmean   SE   df lower.CL upper.CL .group\n BG7049H    19.2 3.57 24.9     11.8     26.5  a    \n 30K64      21.5 3.57 24.9     14.2     28.8  a    \n 30F53 HX   25.0 3.57 24.9     17.7     32.3  a    \n 30F53 YH   26.2 3.57 24.9     18.9     33.6  a    \n 30S31H     26.5 3.57 24.9     19.2     33.8  a    \n 30S31YH    26.6 3.57 24.9     19.3     34.0  a    \n\nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\nm_milho3 &lt;- lmer(yield ~ hybrid*method + \n                  (1 | block:hybrid_block),\n                data = milho)\ncar::Anova(m_milho3)\n\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: yield\n                Chisq Df Pr(&gt;Chisq)    \nhybrid        22.5966  5  0.0004031 ***\nmethod         0.1052  1  0.7456932    \nhybrid:method 25.9302  5  9.206e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nplot(simulateResiduals(m_milho3))\n\n\n\n\n\n\n\n\n\n\n\n\nlibrary(ggplot2)\nmilho |&gt; \n  ggplot(aes(index,  yield))+\n  geom_point()+\n  geom_smooth(method = \"lm\")\n\n\n\n\n\n\n\ncor1 &lt;- cor.test(milho$index, milho$yield)\nR2_percentual &lt;- (cor1$estimate)^2 * 100\nR2_percentual*100\n\n     cor \n632.3713"
  },
  {
    "objectID": "AulaMAPA.html#apresentação-do-site",
    "href": "AulaMAPA.html#apresentação-do-site",
    "title": "Caderno de aulas",
    "section": "Apresentação do site",
    "text": "Apresentação do site\n\nO conjunto de dados será o da ferrugem do café na Etiópia que está no arquivo de dados na nuvem.\n\n\nUtilizamos função gsheet2tbl() do pacote [gsheet] para carregar os dados no ambiente\n\noptions(repos = c(CRAN = \"https://cloud.r-project.org\"))\ninstall.packages(\"sf\")\n\npacote 'sf' desempacotado com sucesso e somas MD5 verificadas\n\nOs pacotes binários baixados estão em\n    C:\\Users\\lucas\\AppData\\Local\\Temp\\RtmpaSrj30\\downloaded_packages\n\nlibrary(gsheet)\ncr &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit?gid=1871397229#gid=1871397229\")\ncr\n\n# A tibble: 405 × 13\n    farm region zone       district      lon   lat altitude cultivar shade    \n   &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;      &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;    \n 1     1 SNNPR  Bench Maji Debub Bench  35.4  6.90     1100 Local    Sun      \n 2     2 SNNPR  Bench Maji Debub Bench  35.4  6.90     1342 Mixture  Mid shade\n 3     3 SNNPR  Bench Maji Debub Bench  35.4  6.90     1434 Mixture  Mid shade\n 4     4 SNNPR  Bench Maji Debub Bench  35.4  6.90     1100 Local    Sun      \n 5     5 SNNPR  Bench Maji Debub Bench  35.4  6.90     1400 Local    Sun      \n 6     6 SNNPR  Bench Maji Debub Bench  35.4  6.90     1342 Mixture  Mid shade\n 7     7 SNNPR  Bench Maji Debub Bench  35.4  6.90     1432 Mixture  Mid shade\n 8     8 SNNPR  Bench Maji Debub Bench  35.4  6.90     1100 Local    Sun      \n 9     9 SNNPR  Bench Maji Debub Bench  35.4  6.89     1400 Local    Sun      \n10    10 SNNPR  Bench Maji Debub Bench  35.4  6.88     1342 Mixture  Mid shade\n# ℹ 395 more rows\n# ℹ 4 more variables: cropping_system &lt;chr&gt;, farm_management &lt;chr&gt;, inc &lt;dbl&gt;,\n#   sev2 &lt;dbl&gt;\n\nlibrary(DT)\ndatatable(cr)\n\n\n\n\nlibrary(tidyverse)\ncr |&gt; \n  ggplot(aes(lon, lat))+\n  geom_point()\n\n\n\n\n\n\n\nremotes::install_github(\"ropensci/rnaturalearthhires\")\n\n* checking for file 'C:\\Users\\lucas\\AppData\\Local\\Temp\\RtmpaSrj30\\remotes1b546e264159\\ropensci-rnaturalearthhires-e4736f6/DESCRIPTION' ... OK\n* preparing 'rnaturalearthhires':\n* checking DESCRIPTION meta-information ... OK\n* checking for LF line-endings in source and make files and shell scripts\n* checking for empty or unneeded directories\n* building 'rnaturalearthhires_1.0.0.9000.tar.gz'\n\nremotes::install_github(\"ropensci/rnaturalearth\")\n\n\nlibrary(rnaturalearth)\ninstall.packages(\"sf\")\n\npacote 'sf' desempacotado com sucesso e somas MD5 verificadas\n\nOs pacotes binários baixados estão em\n    C:\\Users\\lucas\\AppData\\Local\\Temp\\RtmpaSrj30\\downloaded_packages\n\nlibrary(sf)\ninstall.packages(\"earth\")\n\npacote 'earth' desempacotado com sucesso e somas MD5 verificadas\n\nOs pacotes binários baixados estão em\n    C:\\Users\\lucas\\AppData\\Local\\Temp\\RtmpaSrj30\\downloaded_packages\n\nlibrary(earth)\nETH &lt;- ne_states(country = \"Ethiopia\", \n                 returnclass = \"sf\")\n\nlibrary(tidyverse)\nlibrary(ggthemes)\nlibrary(ggspatial)\n\nggplot(ETH)+\n  geom_sf(fill = \"gray90\")+\n  geom_point(data = cr, aes(lon, lat, color = inc))+\n  scale_color_viridis_c()+\n  theme_minimal()+\n  theme(legend.position = \"bottom\")+\n  annotation_scale(location = \"tl\")+\n  annotation_north_arrow(location = \"br\", which_north = \"true\")+\n  labs(title = \"Ferrugem do café na Etiópia\", x = \"longitude\", y= \"latitude\", subtitle = \"levantamento em fazendas\", caption = \"Fonte: Gonçalves et al.(2025)\", \n       color = \"Incidencia (%)\")\n\n\n\n\n\n\n\nggsave(\"mapa.Etiópia.png\", bg = \"white\", width = 10)\n\ninstall.packages(\"rnaturalearthhires\", repos = \"https://packages.ropensci.org\", type = \"source\")\n\nAqui visualizamos os pontos em um gráfico simples, depois carregamos os limites geográficos do país usando o pacote rnaturalearth com o sf. Criamos um mapa temático com o ggplot2, mostrando a localização das fazendas coloridas conforme a incidência da doença. Adicionamos escala e seta de norte, aplicamos um tema limpo e salvamos o mapa em alta qualidade como imagem PNG."
  }
]